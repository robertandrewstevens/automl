{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b71b34ab",
   "metadata": {},
   "source": [
    "https://github.com/h2oai/h2o-tutorials/blob/master/h2o-world-2017/automl/Python/automl_binary_classification_product_backorders.ipynb\n",
    "    \n",
    "# H2O AutoML Binary Classification Demo\n",
    "\n",
    "This is a Jupyter Notebook. When you execute code within the notebook, the results appear beneath the code. To execute a code chunk, place your cursor on the cell and press Shift+Enter.\n",
    "\n",
    "## Start H2O\n",
    "\n",
    "Import the `h2o` Python module and `H2OAutoML` class and initialize a local H2O cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4944ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a15e8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_362\"; OpenJDK Runtime Environment (build 1.8.0_362-b08); OpenJDK 64-Bit Server VM (build 25.362-b08, mixed mode)\n",
      "  Starting server from /home/stever7/.local/lib/python3.9/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpjwlyqx7u\n",
      "  JVM stdout: /tmp/tmpjwlyqx7u/h2o_stever7_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpjwlyqx7u/h2o_stever7_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n",
      "Warning: Your H2O cluster version is too old (1 year, 2 months and 29 days)!Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/GMT</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.36.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 year, 2 months and 29 days !!!</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_stever7_krc30t</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>26.63 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>64</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>64</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.11 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  --------------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       Etc/GMT\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.36.0.3\n",
       "H2O_cluster_version_age:    1 year, 2 months and 29 days !!!\n",
       "H2O_cluster_name:           H2O_from_python_stever7_krc30t\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    26.63 Gb\n",
       "H2O_cluster_total_cores:    64\n",
       "H2O_cluster_allowed_cores:  64\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.11 final\n",
       "--------------------------  --------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8826ef3d",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "For the AutoML binary classification demo, we use a subset of the Product Backorders dataset: \n",
    "\n",
    "https://www.kaggle.com/tiredgeek/predict-bo-trial/data\n",
    "\n",
    "The goal here is to predict whether or not a product will be put on backorder status, given a number of product metrics such as current inventory, transit time, demand forecasts and prior sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b095d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use local data file or download from GitHub\n",
    "\n",
    "import os\n",
    "\n",
    "docker_data_path = \"/home/h2o/data/automl/product_backorders.csv\"\n",
    "\n",
    "if os.path.isfile(docker_data_path):\n",
    "  data_path = docker_data_path\n",
    "else:\n",
    "  data_path = \"https://github.com/h2oai/h2o-tutorials/raw/master/h2o-world-2017/automl/data/product_backorders.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "648f52a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Load data into H2O\n",
    "df = h2o.import_file(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad80ec",
   "metadata": {},
   "source": [
    "For classification, the response should be encoded as categorical (aka. \"factor\" or \"enum\"). Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6a0a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:19053\n",
      "Cols:23\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>sku              </th><th>national_inv      </th><th>lead_time         </th><th>in_transit_qty    </th><th>forecast_3_month  </th><th>forecast_6_month  </th><th>forecast_9_month  </th><th>sales_1_month     </th><th>sales_3_month    </th><th>sales_6_month     </th><th>sales_9_month     </th><th>min_bank         </th><th>potential_issue  </th><th>pieces_past_due   </th><th>perf_6_month_avg  </th><th>perf_12_month_avg  </th><th>local_bo_qty      </th><th>deck_risk  </th><th>oe_constraint  </th><th>ppap_risk  </th><th>stop_auto_buy  </th><th>rev_stop  </th><th>went_on_backorder  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int              </td><td>int               </td><td>int               </td><td>int               </td><td>int               </td><td>int               </td><td>int               </td><td>int               </td><td>int              </td><td>int               </td><td>int               </td><td>int              </td><td>enum             </td><td>int               </td><td>real              </td><td>real               </td><td>int               </td><td>enum       </td><td>enum           </td><td>enum       </td><td>enum           </td><td>enum      </td><td>enum               </td></tr>\n",
       "<tr><td>mins   </td><td>1111620.0        </td><td>-1440.0           </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0               </td><td>0.0              </td><td>0.0               </td><td>0.0               </td><td>0.0              </td><td>                 </td><td>0.0               </td><td>-99.0             </td><td>-99.0              </td><td>0.0               </td><td>           </td><td>               </td><td>           </td><td>               </td><td>          </td><td>                   </td></tr>\n",
       "<tr><td>mean   </td><td>2059552.760562641</td><td>376.36702881435997</td><td>7.706036161335188 </td><td>48.272345562378625</td><td>182.91082769117725</td><td>344.73983099774307</td><td>497.79242114102766</td><td>56.11887891670603 </td><td>168.5344565160342</td><td>333.53219965359784</td><td>504.25539285151933</td><td>48.84070750013121</td><td>                 </td><td>2.311499501390857 </td><td>-6.519833622001784</td><td>-6.05393533826694  </td><td>0.8917755734005144</td><td>           </td><td>               </td><td>           </td><td>               </td><td>          </td><td>                   </td></tr>\n",
       "<tr><td>maxs   </td><td>3284775.0        </td><td>730722.0          </td><td>52.0              </td><td>170920.0          </td><td>479808.0          </td><td>967776.0          </td><td>1418208.0         </td><td>186451.0          </td><td>550609.0         </td><td>1136154.0         </td><td>1759152.0         </td><td>85584.0          </td><td>                 </td><td>13824.0           </td><td>1.0               </td><td>1.0                </td><td>1440.0            </td><td>           </td><td>               </td><td>           </td><td>               </td><td>          </td><td>                   </td></tr>\n",
       "<tr><td>sigma  </td><td>663337.6456498678</td><td>7002.071628662687 </td><td>6.7786650721241895</td><td>1465.999210206829 </td><td>4304.865591970628 </td><td>8406.062155159243 </td><td>12180.570042918358</td><td>1544.2177775482564</td><td>4581.340080221506</td><td>9294.566153218982 </td><td>14184.145395653624</td><td>968.7738680675266</td><td>                 </td><td>110.24106014611986</td><td>25.975138766871876</td><td>25.18449715003253  </td><td>23.033345417338797</td><td>           </td><td>               </td><td>           </td><td>               </td><td>          </td><td>                   </td></tr>\n",
       "<tr><td>zeros  </td><td>0                </td><td>1858              </td><td>121               </td><td>15432             </td><td>12118             </td><td>11136             </td><td>10604             </td><td>10278             </td><td>8022             </td><td>6864              </td><td>6231              </td><td>9909             </td><td>                 </td><td>18601             </td><td>474               </td><td>401                </td><td>18585             </td><td>           </td><td>               </td><td>           </td><td>               </td><td>          </td><td>                   </td></tr>\n",
       "<tr><td>missing</td><td>0                </td><td>0                 </td><td>1078              </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                </td><td>0                 </td><td>0                 </td><td>0                  </td><td>0                 </td><td>0          </td><td>0              </td><td>0          </td><td>0              </td><td>0         </td><td>0                  </td></tr>\n",
       "<tr><td>0      </td><td>1113121.0        </td><td>0.0               </td><td>8.0               </td><td>1.0               </td><td>6.0               </td><td>6.0               </td><td>6.0               </td><td>0.0               </td><td>4.0              </td><td>9.0               </td><td>12.0              </td><td>0.0              </td><td>No               </td><td>1.0               </td><td>0.9               </td><td>0.89               </td><td>0.0               </td><td>No         </td><td>No             </td><td>No         </td><td>Yes            </td><td>No        </td><td>Yes                </td></tr>\n",
       "<tr><td>1      </td><td>1113268.0        </td><td>0.0               </td><td>8.0               </td><td>0.0               </td><td>2.0               </td><td>3.0               </td><td>4.0               </td><td>1.0               </td><td>2.0              </td><td>3.0               </td><td>3.0               </td><td>0.0              </td><td>No               </td><td>0.0               </td><td>0.96              </td><td>0.97               </td><td>0.0               </td><td>No         </td><td>No             </td><td>No         </td><td>Yes            </td><td>No        </td><td>Yes                </td></tr>\n",
       "<tr><td>2      </td><td>1113874.0        </td><td>20.0              </td><td>2.0               </td><td>0.0               </td><td>45.0              </td><td>99.0              </td><td>153.0             </td><td>16.0              </td><td>42.0             </td><td>80.0              </td><td>111.0             </td><td>10.0             </td><td>No               </td><td>0.0               </td><td>0.81              </td><td>0.88               </td><td>0.0               </td><td>No         </td><td>No             </td><td>No         </td><td>Yes            </td><td>No        </td><td>Yes                </td></tr>\n",
       "<tr><td>3      </td><td>1114222.0        </td><td>0.0               </td><td>8.0               </td><td>0.0               </td><td>9.0               </td><td>14.0              </td><td>21.0              </td><td>5.0               </td><td>17.0             </td><td>36.0              </td><td>43.0              </td><td>0.0              </td><td>No               </td><td>0.0               </td><td>0.96              </td><td>0.98               </td><td>0.0               </td><td>No         </td><td>No             </td><td>No         </td><td>Yes            </td><td>No        </td><td>Yes                </td></tr>\n",
       "<tr><td>4      </td><td>1114823.0        </td><td>0.0               </td><td>12.0              </td><td>0.0               </td><td>31.0              </td><td>31.0              </td><td>31.0              </td><td>7.0               </td><td>15.0             </td><td>33.0              </td><td>47.0              </td><td>2.0              </td><td>No               </td><td>3.0               </td><td>0.98              </td><td>0.98               </td><td>0.0               </td><td>No         </td><td>No             </td><td>No         </td><td>Yes            </td><td>No        </td><td>Yes                </td></tr>\n",
       "<tr><td>5      </td><td>1115453.0        </td><td>55.0              </td><td>8.0               </td><td>0.0               </td><td>216.0             </td><td>360.0             </td><td>492.0             </td><td>30.0              </td><td>108.0            </td><td>275.0             </td><td>340.0             </td><td>51.0             </td><td>No               </td><td>0.0               </td><td>0.0               </td><td>0.0                </td><td>0.0               </td><td>No         </td><td>No             </td><td>Yes        </td><td>Yes            </td><td>No        </td><td>Yes                </td></tr>\n",
       "<tr><td>6      </td><td>1115620.0        </td><td>-34.0             </td><td>8.0               </td><td>0.0               </td><td>120.0             </td><td>240.0             </td><td>240.0             </td><td>83.0              </td><td>122.0            </td><td>144.0             </td><td>165.0             </td><td>33.0             </td><td>No               </td><td>0.0               </td><td>1.0               </td><td>0.97               </td><td>34.0              </td><td>No         </td><td>No             </td><td>No         </td><td>Yes            </td><td>No        </td><td>Yes                </td></tr>\n",
       "<tr><td>7      </td><td>1116446.0        </td><td>4.0               </td><td>9.0               </td><td>0.0               </td><td>43.0              </td><td>67.0              </td><td>115.0             </td><td>5.0               </td><td>22.0             </td><td>40.0              </td><td>58.0              </td><td>4.0              </td><td>No               </td><td>0.0               </td><td>0.69              </td><td>0.68               </td><td>0.0               </td><td>No         </td><td>No             </td><td>No         </td><td>Yes            </td><td>No        </td><td>Yes                </td></tr>\n",
       "<tr><td>8      </td><td>1116834.0        </td><td>2.0               </td><td>8.0               </td><td>0.0               </td><td>4.0               </td><td>6.0               </td><td>9.0               </td><td>1.0               </td><td>5.0              </td><td>6.0               </td><td>9.0               </td><td>2.0              </td><td>No               </td><td>0.0               </td><td>1.0               </td><td>0.95               </td><td>0.0               </td><td>No         </td><td>No             </td><td>No         </td><td>Yes            </td><td>No        </td><td>Yes                </td></tr>\n",
       "<tr><td>9      </td><td>1116868.0        </td><td>-7.0              </td><td>8.0               </td><td>0.0               </td><td>56.0              </td><td>96.0              </td><td>112.0             </td><td>13.0              </td><td>30.0             </td><td>56.0              </td><td>76.0              </td><td>0.0              </td><td>No               </td><td>0.0               </td><td>0.97              </td><td>0.92               </td><td>7.0               </td><td>No         </td><td>No             </td><td>No         </td><td>Yes            </td><td>No        </td><td>Yes                </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d353ef8e",
   "metadata": {},
   "source": [
    "We will notice that the response column, `\"went_on_backorder\"`, is already encoded as \"enum\", so there's nothing we need to do here. If it were encoded as a 0/1 \"int\", then we'd have to convert the column as follows: \n",
    "\n",
    "```\n",
    "df[y] = df[y].asfactor()\n",
    "```\n",
    "\n",
    "Next, let's identify the response and predictor columns by saving them as `x` and `y`. The `\"sku\"` column is a unique identifier so we'll want to remove that from the set of our predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d802d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"went_on_backorder\"\n",
    "x = df.columns\n",
    "x.remove(y)\n",
    "x.remove(\"sku\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7664c15",
   "metadata": {},
   "source": [
    "## Run AutoML\n",
    "\n",
    "Run AutoML, stopping after 10 models. The `max_models` argument specifies the number of individual (or \"base\") models, and does not include the two ensemble models that are trained at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4916e25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_2_AutoML_1_20230516_144637\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.03097148348640562\n",
      "RMSE: 0.17598716852772425\n",
      "LogLoss: 0.11079814450057998\n",
      "Null degrees of freedom: 10047\n",
      "Residual degrees of freedom: 10039\n",
      "Null deviance: 7374.795081759208\n",
      "Residual deviance: 2226.5995118836554\n",
      "AIC: 2244.5995118836554\n",
      "AUC: 0.9832933087709308\n",
      "AUCPR: 0.9153846924589029\n",
      "Gini: 0.9665866175418616\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4489343354104793: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>8687.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>(155.0/8842.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>237.0</td>\n",
       "      <td>969.0</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>(237.0/1206.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>8924.0</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>(392.0/10048.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              No     Yes   Error              Rate\n",
       "0     No  8687.0   155.0  0.0175    (155.0/8842.0)\n",
       "1    Yes   237.0   969.0  0.1965    (237.0/1206.0)\n",
       "2  Total  8924.0  1124.0   0.039   (392.0/10048.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.448934</td>\n",
       "      <td>0.831760</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.184645</td>\n",
       "      <td>0.860625</td>\n",
       "      <td>254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.559863</td>\n",
       "      <td>0.871678</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.518455</td>\n",
       "      <td>0.961087</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.992345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.992345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.448934</td>\n",
       "      <td>0.810368</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.188597</td>\n",
       "      <td>0.932481</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.157812</td>\n",
       "      <td>0.935691</td>\n",
       "      <td>267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.992345</td>\n",
       "      <td>8842.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.992345</td>\n",
       "      <td>1203.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>8842.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>1206.000000</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.992345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.992345</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.448934     0.831760  168.0\n",
       "1                        max f2   0.184645     0.860625  254.0\n",
       "2                  max f0point5   0.559863     0.871678  136.0\n",
       "3                  max accuracy   0.518455     0.961087  147.0\n",
       "4                 max precision   0.992345     1.000000    0.0\n",
       "5                    max recall   0.004086     1.000000  388.0\n",
       "6               max specificity   0.992345     1.000000    0.0\n",
       "7              max absolute_mcc   0.448934     0.810368  168.0\n",
       "8    max min_per_class_accuracy   0.188597     0.932481  252.0\n",
       "9   max mean_per_class_accuracy   0.157812     0.935691  267.0\n",
       "10                      max tns   0.992345  8842.000000    0.0\n",
       "11                      max fns   0.992345  1203.000000    0.0\n",
       "12                      max fps   0.000405  8842.000000  399.0\n",
       "13                      max tps   0.004086  1206.000000  388.0\n",
       "14                      max tnr   0.992345     1.000000    0.0\n",
       "15                      max fnr   0.992345     0.997512    0.0\n",
       "16                      max fpr   0.000405     1.000000  399.0\n",
       "17                      max tpr   0.004086     1.000000  388.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 12.00 %, avg score: 12.18 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>0.952543</td>\n",
       "      <td>8.331675</td>\n",
       "      <td>8.331675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968387</td>\n",
       "      <td>0.083748</td>\n",
       "      <td>0.083748</td>\n",
       "      <td>733.167496</td>\n",
       "      <td>733.167496</td>\n",
       "      <td>0.083748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.924404</td>\n",
       "      <td>8.331675</td>\n",
       "      <td>8.331675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953321</td>\n",
       "      <td>0.082919</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>733.167496</td>\n",
       "      <td>733.167496</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030056</td>\n",
       "      <td>0.898838</td>\n",
       "      <td>8.249183</td>\n",
       "      <td>8.304087</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.912033</td>\n",
       "      <td>0.996689</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.082919</td>\n",
       "      <td>0.249585</td>\n",
       "      <td>724.918313</td>\n",
       "      <td>730.408663</td>\n",
       "      <td>0.249472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040008</td>\n",
       "      <td>0.866620</td>\n",
       "      <td>8.331675</td>\n",
       "      <td>8.310949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882842</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>0.925415</td>\n",
       "      <td>0.082919</td>\n",
       "      <td>0.332504</td>\n",
       "      <td>733.167496</td>\n",
       "      <td>731.094940</td>\n",
       "      <td>0.332391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050060</td>\n",
       "      <td>0.825395</td>\n",
       "      <td>8.001708</td>\n",
       "      <td>8.248855</td>\n",
       "      <td>0.960396</td>\n",
       "      <td>0.846546</td>\n",
       "      <td>0.990060</td>\n",
       "      <td>0.909579</td>\n",
       "      <td>0.080431</td>\n",
       "      <td>0.412935</td>\n",
       "      <td>700.170763</td>\n",
       "      <td>724.885513</td>\n",
       "      <td>0.412370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100020</td>\n",
       "      <td>0.526157</td>\n",
       "      <td>6.771561</td>\n",
       "      <td>7.510943</td>\n",
       "      <td>0.812749</td>\n",
       "      <td>0.685489</td>\n",
       "      <td>0.901493</td>\n",
       "      <td>0.797646</td>\n",
       "      <td>0.338308</td>\n",
       "      <td>0.751244</td>\n",
       "      <td>577.156052</td>\n",
       "      <td>651.094280</td>\n",
       "      <td>0.740047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150080</td>\n",
       "      <td>0.265646</td>\n",
       "      <td>2.898694</td>\n",
       "      <td>5.972507</td>\n",
       "      <td>0.347913</td>\n",
       "      <td>0.382853</td>\n",
       "      <td>0.716844</td>\n",
       "      <td>0.659290</td>\n",
       "      <td>0.145108</td>\n",
       "      <td>0.896352</td>\n",
       "      <td>189.869407</td>\n",
       "      <td>497.250705</td>\n",
       "      <td>0.848059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200040</td>\n",
       "      <td>0.125508</td>\n",
       "      <td>1.294563</td>\n",
       "      <td>4.804185</td>\n",
       "      <td>0.155378</td>\n",
       "      <td>0.185555</td>\n",
       "      <td>0.576617</td>\n",
       "      <td>0.540974</td>\n",
       "      <td>0.064677</td>\n",
       "      <td>0.961028</td>\n",
       "      <td>29.456304</td>\n",
       "      <td>380.418471</td>\n",
       "      <td>0.864783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300060</td>\n",
       "      <td>0.040366</td>\n",
       "      <td>0.298448</td>\n",
       "      <td>3.302272</td>\n",
       "      <td>0.035821</td>\n",
       "      <td>0.071735</td>\n",
       "      <td>0.396352</td>\n",
       "      <td>0.384561</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>-70.155194</td>\n",
       "      <td>230.227250</td>\n",
       "      <td>0.785043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399980</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.082985</td>\n",
       "      <td>2.498051</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.027384</td>\n",
       "      <td>0.299826</td>\n",
       "      <td>0.295333</td>\n",
       "      <td>0.008292</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>-91.701519</td>\n",
       "      <td>149.805134</td>\n",
       "      <td>0.680917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.998342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014351</td>\n",
       "      <td>0.239849</td>\n",
       "      <td>0.239126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>99.834163</td>\n",
       "      <td>0.567255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600020</td>\n",
       "      <td>0.006890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.665229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008712</td>\n",
       "      <td>0.199867</td>\n",
       "      <td>0.200717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>66.522945</td>\n",
       "      <td>0.453593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699940</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.427509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.171335</td>\n",
       "      <td>0.172876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>42.750865</td>\n",
       "      <td>0.340044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799960</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>1.250062</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.150037</td>\n",
       "      <td>0.151764</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.170978</td>\n",
       "      <td>25.006220</td>\n",
       "      <td>0.227324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899980</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>0.133363</td>\n",
       "      <td>0.135215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.113569</td>\n",
       "      <td>0.113662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.120024</td>\n",
       "      <td>0.121829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010052         0.952543  8.331675   \n",
       "1       2                  0.020004         0.924404  8.331675   \n",
       "2       3                  0.030056         0.898838  8.249183   \n",
       "3       4                  0.040008         0.866620  8.331675   \n",
       "4       5                  0.050060         0.825395  8.001708   \n",
       "5       6                  0.100020         0.526157  6.771561   \n",
       "6       7                  0.150080         0.265646  2.898694   \n",
       "7       8                  0.200040         0.125508  1.294563   \n",
       "8       9                  0.300060         0.040366  0.298448   \n",
       "9      10                  0.399980         0.018730  0.082985   \n",
       "10     11                  0.500000         0.010939  0.000000   \n",
       "11     12                  0.600020         0.006890  0.000000   \n",
       "12     13                  0.699940         0.004727  0.000000   \n",
       "13     14                  0.799960         0.003441  0.008290   \n",
       "14     15                  0.899980         0.002187  0.000000   \n",
       "15     16                  1.000000         0.000010  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          8.331675       1.000000  0.968387                  1.000000   \n",
       "1          8.331675       1.000000  0.938104                  1.000000   \n",
       "2          8.304087       0.990099  0.912033                  0.996689   \n",
       "3          8.310949       1.000000  0.882842                  0.997512   \n",
       "4          8.248855       0.960396  0.846546                  0.990060   \n",
       "5          7.510943       0.812749  0.685489                  0.901493   \n",
       "6          5.972507       0.347913  0.382853                  0.716844   \n",
       "7          4.804185       0.155378  0.185555                  0.576617   \n",
       "8          3.302272       0.035821  0.071735                  0.396352   \n",
       "9          2.498051       0.009960  0.027384                  0.299826   \n",
       "10         1.998342       0.000000  0.014351                  0.239849   \n",
       "11         1.665229       0.000000  0.008712                  0.199867   \n",
       "12         1.427509       0.000000  0.005693                  0.171335   \n",
       "13         1.250062       0.000995  0.004016                  0.150037   \n",
       "14         1.111136       0.000000  0.002856                  0.133363   \n",
       "15         1.000000       0.000000  0.001389                  0.120024   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.968387      0.083748                 0.083748  733.167496   \n",
       "1           0.953321      0.082919                 0.166667  733.167496   \n",
       "2           0.939513      0.082919                 0.249585  724.918313   \n",
       "3           0.925415      0.082919                 0.332504  733.167496   \n",
       "4           0.909579      0.080431                 0.412935  700.170763   \n",
       "5           0.797646      0.338308                 0.751244  577.156052   \n",
       "6           0.659290      0.145108                 0.896352  189.869407   \n",
       "7           0.540974      0.064677                 0.961028   29.456304   \n",
       "8           0.384561      0.029851                 0.990879  -70.155194   \n",
       "9           0.295333      0.008292                 0.999171  -91.701519   \n",
       "10          0.239126      0.000000                 0.999171 -100.000000   \n",
       "11          0.200717      0.000000                 0.999171 -100.000000   \n",
       "12          0.172876      0.000000                 0.999171 -100.000000   \n",
       "13          0.151764      0.000829                 1.000000  -99.170978   \n",
       "14          0.135215      0.000000                 1.000000 -100.000000   \n",
       "15          0.121829      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        733.167496            0.083748  \n",
       "1        733.167496            0.166667  \n",
       "2        730.408663            0.249472  \n",
       "3        731.094940            0.332391  \n",
       "4        724.885513            0.412370  \n",
       "5        651.094280            0.740047  \n",
       "6        497.250705            0.848059  \n",
       "7        380.418471            0.864783  \n",
       "8        230.227250            0.785043  \n",
       "9        149.805134            0.680917  \n",
       "10        99.834163            0.567255  \n",
       "11        66.522945            0.453593  \n",
       "12        42.750865            0.340044  \n",
       "13        25.006220            0.227324  \n",
       "14        11.113569            0.113662  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.04986141819777073\n",
      "RMSE: 0.2232967044041867\n",
      "LogLoss: 0.16851530957102018\n",
      "Null degrees of freedom: 19052\n",
      "Residual degrees of freedom: 19045\n",
      "Null deviance: 13901.345057634844\n",
      "Residual deviance: 6421.44438651331\n",
      "AIC: 6437.44438651331\n",
      "AUC: 0.9518747064552273\n",
      "AUCPR: 0.7521982063914671\n",
      "Gini: 0.9037494129104546\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3576163957857999: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>16017.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>(770.0/16787.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>596.0</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>(596.0/2266.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>16613.0</td>\n",
       "      <td>2440.0</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>(1366.0/19053.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               No     Yes   Error               Rate\n",
       "0     No  16017.0   770.0  0.0459    (770.0/16787.0)\n",
       "1    Yes    596.0  1670.0   0.263     (596.0/2266.0)\n",
       "2  Total  16613.0  2440.0  0.0717   (1366.0/19053.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.357616</td>\n",
       "      <td>0.709732</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.141452</td>\n",
       "      <td>0.779748</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.587133</td>\n",
       "      <td>0.737230</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.525077</td>\n",
       "      <td>0.932662</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.982298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.982298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.407997</td>\n",
       "      <td>0.669723</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.128705</td>\n",
       "      <td>0.888791</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.101517</td>\n",
       "      <td>0.891015</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.982298</td>\n",
       "      <td>16787.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.982298</td>\n",
       "      <td>2260.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>16787.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>2266.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.982298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.982298</td>\n",
       "      <td>0.997352</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.357616      0.709732  198.0\n",
       "1                        max f2   0.141452      0.779748  278.0\n",
       "2                  max f0point5   0.587133      0.737230  129.0\n",
       "3                  max accuracy   0.525077      0.932662  146.0\n",
       "4                 max precision   0.982298      1.000000    0.0\n",
       "5                    max recall   0.000356      1.000000  399.0\n",
       "6               max specificity   0.982298      1.000000    0.0\n",
       "7              max absolute_mcc   0.407997      0.669723  181.0\n",
       "8    max min_per_class_accuracy   0.128705      0.888791  284.0\n",
       "9   max mean_per_class_accuracy   0.101517      0.891015  299.0\n",
       "10                      max tns   0.982298  16787.000000    0.0\n",
       "11                      max fns   0.982298   2260.000000    0.0\n",
       "12                      max fps   0.000356  16787.000000  399.0\n",
       "13                      max tps   0.000356   2266.000000  399.0\n",
       "14                      max tnr   0.982298      1.000000    0.0\n",
       "15                      max fnr   0.982298      0.997352    0.0\n",
       "16                      max fpr   0.000356      1.000000  399.0\n",
       "17                      max tpr   0.000356      1.000000  399.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 11.89 %, avg score: 11.89 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>9.310959e-01</td>\n",
       "      <td>7.527768</td>\n",
       "      <td>7.527768</td>\n",
       "      <td>0.895288</td>\n",
       "      <td>0.952280</td>\n",
       "      <td>0.895288</td>\n",
       "      <td>0.952280</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>0.075463</td>\n",
       "      <td>652.776764</td>\n",
       "      <td>652.776764</td>\n",
       "      <td>0.074272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020049</td>\n",
       "      <td>8.965254e-01</td>\n",
       "      <td>7.439724</td>\n",
       "      <td>7.483746</td>\n",
       "      <td>0.884817</td>\n",
       "      <td>0.913610</td>\n",
       "      <td>0.890052</td>\n",
       "      <td>0.932945</td>\n",
       "      <td>0.074581</td>\n",
       "      <td>0.150044</td>\n",
       "      <td>643.972357</td>\n",
       "      <td>648.374560</td>\n",
       "      <td>0.147542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030022</td>\n",
       "      <td>8.625843e-01</td>\n",
       "      <td>7.346119</td>\n",
       "      <td>7.438030</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.879388</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.915155</td>\n",
       "      <td>0.073257</td>\n",
       "      <td>0.223301</td>\n",
       "      <td>634.611883</td>\n",
       "      <td>643.803042</td>\n",
       "      <td>0.219369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040046</td>\n",
       "      <td>8.220495e-01</td>\n",
       "      <td>7.131569</td>\n",
       "      <td>7.361315</td>\n",
       "      <td>0.848168</td>\n",
       "      <td>0.843614</td>\n",
       "      <td>0.875491</td>\n",
       "      <td>0.897246</td>\n",
       "      <td>0.071492</td>\n",
       "      <td>0.294793</td>\n",
       "      <td>613.156934</td>\n",
       "      <td>636.131473</td>\n",
       "      <td>0.289133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050018</td>\n",
       "      <td>7.761968e-01</td>\n",
       "      <td>6.947835</td>\n",
       "      <td>7.278879</td>\n",
       "      <td>0.826316</td>\n",
       "      <td>0.800765</td>\n",
       "      <td>0.865687</td>\n",
       "      <td>0.878011</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>0.364078</td>\n",
       "      <td>594.783528</td>\n",
       "      <td>627.887917</td>\n",
       "      <td>0.356453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>5.005465e-01</td>\n",
       "      <td>5.426074</td>\n",
       "      <td>6.352476</td>\n",
       "      <td>0.645331</td>\n",
       "      <td>0.644452</td>\n",
       "      <td>0.755509</td>\n",
       "      <td>0.761231</td>\n",
       "      <td>0.271403</td>\n",
       "      <td>0.635481</td>\n",
       "      <td>442.607356</td>\n",
       "      <td>535.247636</td>\n",
       "      <td>0.607721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150003</td>\n",
       "      <td>2.663714e-01</td>\n",
       "      <td>3.197239</td>\n",
       "      <td>5.301467</td>\n",
       "      <td>0.380252</td>\n",
       "      <td>0.371692</td>\n",
       "      <td>0.630511</td>\n",
       "      <td>0.631476</td>\n",
       "      <td>0.159753</td>\n",
       "      <td>0.795234</td>\n",
       "      <td>219.723887</td>\n",
       "      <td>430.146653</td>\n",
       "      <td>0.732328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>1.336486e-01</td>\n",
       "      <td>1.773400</td>\n",
       "      <td>4.419218</td>\n",
       "      <td>0.210913</td>\n",
       "      <td>0.191998</td>\n",
       "      <td>0.525584</td>\n",
       "      <td>0.521578</td>\n",
       "      <td>0.088703</td>\n",
       "      <td>0.883936</td>\n",
       "      <td>77.339965</td>\n",
       "      <td>341.921837</td>\n",
       "      <td>0.776234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300005</td>\n",
       "      <td>4.340499e-02</td>\n",
       "      <td>0.648822</td>\n",
       "      <td>3.162640</td>\n",
       "      <td>0.077165</td>\n",
       "      <td>0.076804</td>\n",
       "      <td>0.376137</td>\n",
       "      <td>0.373346</td>\n",
       "      <td>0.064872</td>\n",
       "      <td>0.948808</td>\n",
       "      <td>-35.117763</td>\n",
       "      <td>216.263958</td>\n",
       "      <td>0.736382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399990</td>\n",
       "      <td>2.063023e-02</td>\n",
       "      <td>0.242757</td>\n",
       "      <td>2.432765</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>0.030031</td>\n",
       "      <td>0.289332</td>\n",
       "      <td>0.287528</td>\n",
       "      <td>0.024272</td>\n",
       "      <td>0.973080</td>\n",
       "      <td>-75.724333</td>\n",
       "      <td>143.276464</td>\n",
       "      <td>0.650450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500026</td>\n",
       "      <td>1.182531e-02</td>\n",
       "      <td>0.119109</td>\n",
       "      <td>1.969888</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>0.015637</td>\n",
       "      <td>0.234282</td>\n",
       "      <td>0.233133</td>\n",
       "      <td>0.011915</td>\n",
       "      <td>0.984996</td>\n",
       "      <td>-88.089107</td>\n",
       "      <td>96.988778</td>\n",
       "      <td>0.550433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600010</td>\n",
       "      <td>7.381224e-03</td>\n",
       "      <td>0.097103</td>\n",
       "      <td>1.657812</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>0.009429</td>\n",
       "      <td>0.197166</td>\n",
       "      <td>0.195855</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.994704</td>\n",
       "      <td>-90.289733</td>\n",
       "      <td>65.781154</td>\n",
       "      <td>0.447972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699995</td>\n",
       "      <td>4.851880e-03</td>\n",
       "      <td>0.030896</td>\n",
       "      <td>1.425430</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>0.169528</td>\n",
       "      <td>0.168738</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>0.997793</td>\n",
       "      <td>-96.910370</td>\n",
       "      <td>42.542993</td>\n",
       "      <td>0.337997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799979</td>\n",
       "      <td>3.317604e-03</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>1.247826</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.148406</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.998235</td>\n",
       "      <td>-99.558624</td>\n",
       "      <td>24.782621</td>\n",
       "      <td>0.225017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899963</td>\n",
       "      <td>2.048482e-03</td>\n",
       "      <td>0.013241</td>\n",
       "      <td>1.110666</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.132093</td>\n",
       "      <td>0.131990</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.999559</td>\n",
       "      <td>-98.675873</td>\n",
       "      <td>11.066611</td>\n",
       "      <td>0.113039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.300000e-07</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.118931</td>\n",
       "      <td>0.118917</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.558856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010025     9.310959e-01  7.527768   \n",
       "1       2                  0.020049     8.965254e-01  7.439724   \n",
       "2       3                  0.030022     8.625843e-01  7.346119   \n",
       "3       4                  0.040046     8.220495e-01  7.131569   \n",
       "4       5                  0.050018     7.761968e-01  6.947835   \n",
       "5       6                  0.100037     5.005465e-01  5.426074   \n",
       "6       7                  0.150003     2.663714e-01  3.197239   \n",
       "7       8                  0.200021     1.336486e-01  1.773400   \n",
       "8       9                  0.300005     4.340499e-02  0.648822   \n",
       "9      10                  0.399990     2.063023e-02  0.242757   \n",
       "10     11                  0.500026     1.182531e-02  0.119109   \n",
       "11     12                  0.600010     7.381224e-03  0.097103   \n",
       "12     13                  0.699995     4.851880e-03  0.030896   \n",
       "13     14                  0.799979     3.317604e-03  0.004414   \n",
       "14     15                  0.899963     2.048482e-03  0.013241   \n",
       "15     16                  1.000000     4.300000e-07  0.004411   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          7.527768       0.895288  0.952280                  0.895288   \n",
       "1          7.483746       0.884817  0.913610                  0.890052   \n",
       "2          7.438030       0.873684  0.879388                  0.884615   \n",
       "3          7.361315       0.848168  0.843614                  0.875491   \n",
       "4          7.278879       0.826316  0.800765                  0.865687   \n",
       "5          6.352476       0.645331  0.644452                  0.755509   \n",
       "6          5.301467       0.380252  0.371692                  0.630511   \n",
       "7          4.419218       0.210913  0.191998                  0.525584   \n",
       "8          3.162640       0.077165  0.076804                  0.376137   \n",
       "9          2.432765       0.028871  0.030031                  0.289332   \n",
       "10         1.969888       0.014166  0.015637                  0.234282   \n",
       "11         1.657812       0.011549  0.009429                  0.197166   \n",
       "12         1.425430       0.003675  0.006002                  0.169528   \n",
       "13         1.247826       0.000525  0.004016                  0.148406   \n",
       "14         1.110666       0.001575  0.002690                  0.132093   \n",
       "15         1.000000       0.000525  0.001315                  0.118931   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.952280      0.075463                 0.075463  652.776764   \n",
       "1           0.932945      0.074581                 0.150044  643.972357   \n",
       "2           0.915155      0.073257                 0.223301  634.611883   \n",
       "3           0.897246      0.071492                 0.294793  613.156934   \n",
       "4           0.878011      0.069285                 0.364078  594.783528   \n",
       "5           0.761231      0.271403                 0.635481  442.607356   \n",
       "6           0.631476      0.159753                 0.795234  219.723887   \n",
       "7           0.521578      0.088703                 0.883936   77.339965   \n",
       "8           0.373346      0.064872                 0.948808  -35.117763   \n",
       "9           0.287528      0.024272                 0.973080  -75.724333   \n",
       "10          0.233133      0.011915                 0.984996  -88.089107   \n",
       "11          0.195855      0.009709                 0.994704  -90.289733   \n",
       "12          0.168738      0.003089                 0.997793  -96.910370   \n",
       "13          0.148150      0.000441                 0.998235  -99.558624   \n",
       "14          0.131990      0.001324                 0.999559  -98.675873   \n",
       "15          0.118917      0.000441                 1.000000  -99.558856   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        652.776764            0.074272  \n",
       "1        648.374560            0.147542  \n",
       "2        643.803042            0.219369  \n",
       "3        636.131473            0.289133  \n",
       "4        627.887917            0.356453  \n",
       "5        535.247636            0.607721  \n",
       "6        430.146653            0.732328  \n",
       "7        341.921837            0.776234  \n",
       "8        216.263958            0.736382  \n",
       "9        143.276464            0.650450  \n",
       "10        96.988778            0.550433  \n",
       "11        65.781154            0.447972  \n",
       "12        42.542993            0.337997  \n",
       "13        24.782621            0.225017  \n",
       "14        11.066611            0.113039  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml = H2OAutoML(max_models=10, seed=1)\n",
    "aml.train(x=x, y=y, training_frame=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa68650b",
   "metadata": {},
   "source": [
    "*Note: If you see the following error, it means that you need to install the pandas module.*\n",
    "\n",
    "```\n",
    "H2OTypeError: Argument `python_obj` should be a None | list | tuple | dict | numpy.ndarray | pandas.DataFrame | scipy.sparse.issparse, got H2OTwoDimTable \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1b057",
   "metadata": {},
   "source": [
    "## Leaderboard\n",
    "\n",
    "Next, we will view the AutoML Leaderboard. Since we did not specify a `leaderboard_frame` in the `H2OAutoML.train()` method for scoring and ranking the models, the AutoML leaderboard uses cross-validation metrics to rank the models.\n",
    "\n",
    "A default performance metric for each machine learning task (binary classification, multiclass classification, regression) is specified internally and the leaderboard will be sorted by that metric. In the case of binary classification, the default ranking metric is Area Under the ROC Curve (AUC). In the future, the user will be able to specify any of the H2O metrics so that different metrics can be used to generate rankings on the leaderboard.\n",
    "\n",
    "The leader model is stored at `aml.leader` and the leaderboard is stored at `aml.leaderboard`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83b32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = aml.leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85121283",
   "metadata": {},
   "source": [
    "Now we will view a snapshot of the top models. Here we should see the two Stacked Ensembles at or near the top of the leaderboard. Stacked Ensembles can almost always outperform a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6cb181c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                               </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_2_AutoML_1_20230516_144637   </td><td style=\"text-align: right;\">0.951875</td><td style=\"text-align: right;\"> 0.168515</td><td style=\"text-align: right;\">0.752198</td><td style=\"text-align: right;\">              0.154444</td><td style=\"text-align: right;\">0.223297</td><td style=\"text-align: right;\">0.0498614</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_5_AutoML_1_20230516_144637   </td><td style=\"text-align: right;\">0.951784</td><td style=\"text-align: right;\"> 0.168695</td><td style=\"text-align: right;\">0.751926</td><td style=\"text-align: right;\">              0.155046</td><td style=\"text-align: right;\">0.223387</td><td style=\"text-align: right;\">0.0499016</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_3_AutoML_1_20230516_144637</td><td style=\"text-align: right;\">0.951759</td><td style=\"text-align: right;\"> 0.168899</td><td style=\"text-align: right;\">0.751959</td><td style=\"text-align: right;\">              0.153113</td><td style=\"text-align: right;\">0.223442</td><td style=\"text-align: right;\">0.0499262</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_2_AutoML_1_20230516_144637</td><td style=\"text-align: right;\">0.951351</td><td style=\"text-align: right;\"> 0.169659</td><td style=\"text-align: right;\">0.74926 </td><td style=\"text-align: right;\">              0.158555</td><td style=\"text-align: right;\">0.224003</td><td style=\"text-align: right;\">0.0501773</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_6_AutoML_1_20230516_144637</td><td style=\"text-align: right;\">0.951215</td><td style=\"text-align: right;\"> 0.169459</td><td style=\"text-align: right;\">0.749805</td><td style=\"text-align: right;\">              0.161316</td><td style=\"text-align: right;\">0.223739</td><td style=\"text-align: right;\">0.0500589</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_1_20230516_144637   </td><td style=\"text-align: right;\">0.951146</td><td style=\"text-align: right;\"> 0.16959 </td><td style=\"text-align: right;\">0.749583</td><td style=\"text-align: right;\">              0.156424</td><td style=\"text-align: right;\">0.224023</td><td style=\"text-align: right;\">0.0501862</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_5_AutoML_1_20230516_144637</td><td style=\"text-align: right;\">0.950136</td><td style=\"text-align: right;\"> 0.170448</td><td style=\"text-align: right;\">0.744467</td><td style=\"text-align: right;\">              0.149462</td><td style=\"text-align: right;\">0.224544</td><td style=\"text-align: right;\">0.0504198</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_4_AutoML_1_20230516_144637   </td><td style=\"text-align: right;\">0.950104</td><td style=\"text-align: right;\"> 0.170762</td><td style=\"text-align: right;\">0.743876</td><td style=\"text-align: right;\">              0.159872</td><td style=\"text-align: right;\">0.224988</td><td style=\"text-align: right;\">0.0506195</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_1_20230516_144637</td><td style=\"text-align: right;\">0.948265</td><td style=\"text-align: right;\"> 0.173242</td><td style=\"text-align: right;\">0.739868</td><td style=\"text-align: right;\">              0.154965</td><td style=\"text-align: right;\">0.226638</td><td style=\"text-align: right;\">0.0513648</td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20230516_144637                         </td><td style=\"text-align: right;\">0.947608</td><td style=\"text-align: right;\"> 0.17478 </td><td style=\"text-align: right;\">0.737148</td><td style=\"text-align: right;\">              0.163658</td><td style=\"text-align: right;\">0.227059</td><td style=\"text-align: right;\">0.0515557</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f433c6d0",
   "metadata": {},
   "source": [
    "To view the entire leaderboard, specify the `rows` argument of the `head()` method as the total number of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "056c9092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                               </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_2_AutoML_1_20230516_144637   </td><td style=\"text-align: right;\">0.951875</td><td style=\"text-align: right;\"> 0.168515</td><td style=\"text-align: right;\">0.752198</td><td style=\"text-align: right;\">              0.154444</td><td style=\"text-align: right;\">0.223297</td><td style=\"text-align: right;\">0.0498614</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_5_AutoML_1_20230516_144637   </td><td style=\"text-align: right;\">0.951784</td><td style=\"text-align: right;\"> 0.168695</td><td style=\"text-align: right;\">0.751926</td><td style=\"text-align: right;\">              0.155046</td><td style=\"text-align: right;\">0.223387</td><td style=\"text-align: right;\">0.0499016</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_3_AutoML_1_20230516_144637</td><td style=\"text-align: right;\">0.951759</td><td style=\"text-align: right;\"> 0.168899</td><td style=\"text-align: right;\">0.751959</td><td style=\"text-align: right;\">              0.153113</td><td style=\"text-align: right;\">0.223442</td><td style=\"text-align: right;\">0.0499262</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_2_AutoML_1_20230516_144637</td><td style=\"text-align: right;\">0.951351</td><td style=\"text-align: right;\"> 0.169659</td><td style=\"text-align: right;\">0.74926 </td><td style=\"text-align: right;\">              0.158555</td><td style=\"text-align: right;\">0.224003</td><td style=\"text-align: right;\">0.0501773</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_6_AutoML_1_20230516_144637</td><td style=\"text-align: right;\">0.951215</td><td style=\"text-align: right;\"> 0.169459</td><td style=\"text-align: right;\">0.749805</td><td style=\"text-align: right;\">              0.161316</td><td style=\"text-align: right;\">0.223739</td><td style=\"text-align: right;\">0.0500589</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_1_20230516_144637   </td><td style=\"text-align: right;\">0.951146</td><td style=\"text-align: right;\"> 0.16959 </td><td style=\"text-align: right;\">0.749583</td><td style=\"text-align: right;\">              0.156424</td><td style=\"text-align: right;\">0.224023</td><td style=\"text-align: right;\">0.0501862</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_5_AutoML_1_20230516_144637</td><td style=\"text-align: right;\">0.950136</td><td style=\"text-align: right;\"> 0.170448</td><td style=\"text-align: right;\">0.744467</td><td style=\"text-align: right;\">              0.149462</td><td style=\"text-align: right;\">0.224544</td><td style=\"text-align: right;\">0.0504198</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_4_AutoML_1_20230516_144637   </td><td style=\"text-align: right;\">0.950104</td><td style=\"text-align: right;\"> 0.170762</td><td style=\"text-align: right;\">0.743876</td><td style=\"text-align: right;\">              0.159872</td><td style=\"text-align: right;\">0.224988</td><td style=\"text-align: right;\">0.0506195</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_1_20230516_144637</td><td style=\"text-align: right;\">0.948265</td><td style=\"text-align: right;\"> 0.173242</td><td style=\"text-align: right;\">0.739868</td><td style=\"text-align: right;\">              0.154965</td><td style=\"text-align: right;\">0.226638</td><td style=\"text-align: right;\">0.0513648</td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20230516_144637                         </td><td style=\"text-align: right;\">0.947608</td><td style=\"text-align: right;\"> 0.17478 </td><td style=\"text-align: right;\">0.737148</td><td style=\"text-align: right;\">              0.163658</td><td style=\"text-align: right;\">0.227059</td><td style=\"text-align: right;\">0.0515557</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_3_AutoML_1_20230516_144637   </td><td style=\"text-align: right;\">0.947354</td><td style=\"text-align: right;\"> 0.177602</td><td style=\"text-align: right;\">0.733894</td><td style=\"text-align: right;\">              0.166546</td><td style=\"text-align: right;\">0.228117</td><td style=\"text-align: right;\">0.0520372</td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_1_20230516_144637                     </td><td style=\"text-align: right;\">0.946914</td><td style=\"text-align: right;\"> 0.175284</td><td style=\"text-align: right;\">0.73543 </td><td style=\"text-align: right;\">              0.165812</td><td style=\"text-align: right;\">0.227375</td><td style=\"text-align: right;\">0.0516993</td></tr>\n",
       "<tr><td>GBM_1_AutoML_1_20230516_144637                         </td><td style=\"text-align: right;\">0.946849</td><td style=\"text-align: right;\"> 0.175838</td><td style=\"text-align: right;\">0.736278</td><td style=\"text-align: right;\">              0.161556</td><td style=\"text-align: right;\">0.228859</td><td style=\"text-align: right;\">0.0523764</td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20230516_144637                         </td><td style=\"text-align: right;\">0.946584</td><td style=\"text-align: right;\"> 0.176847</td><td style=\"text-align: right;\">0.734336</td><td style=\"text-align: right;\">              0.158497</td><td style=\"text-align: right;\">0.228157</td><td style=\"text-align: right;\">0.0520556</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_4_AutoML_1_20230516_144637</td><td style=\"text-align: right;\">0.946402</td><td style=\"text-align: right;\"> 0.17618 </td><td style=\"text-align: right;\">0.738922</td><td style=\"text-align: right;\">              0.155601</td><td style=\"text-align: right;\">0.226221</td><td style=\"text-align: right;\">0.0511759</td></tr>\n",
       "<tr><td>GBM_2_AutoML_1_20230516_144637                         </td><td style=\"text-align: right;\">0.945185</td><td style=\"text-align: right;\"> 0.179422</td><td style=\"text-align: right;\">0.729203</td><td style=\"text-align: right;\">              0.166895</td><td style=\"text-align: right;\">0.230005</td><td style=\"text-align: right;\">0.0529024</td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_1_20230516_144637                     </td><td style=\"text-align: right;\">0.94448 </td><td style=\"text-align: right;\"> 0.182161</td><td style=\"text-align: right;\">0.723433</td><td style=\"text-align: right;\">              0.155024</td><td style=\"text-align: right;\">0.230922</td><td style=\"text-align: right;\">0.0533252</td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_1_20230516_144637                     </td><td style=\"text-align: right;\">0.9427  </td><td style=\"text-align: right;\"> 0.18251 </td><td style=\"text-align: right;\">0.718273</td><td style=\"text-align: right;\">              0.160809</td><td style=\"text-align: right;\">0.231157</td><td style=\"text-align: right;\">0.0534336</td></tr>\n",
       "<tr><td>XRT_1_AutoML_1_20230516_144637                         </td><td style=\"text-align: right;\">0.940085</td><td style=\"text-align: right;\"> 0.213431</td><td style=\"text-align: right;\">0.723229</td><td style=\"text-align: right;\">              0.164228</td><td style=\"text-align: right;\">0.245723</td><td style=\"text-align: right;\">0.0603798</td></tr>\n",
       "<tr><td>DRF_1_AutoML_1_20230516_144637                         </td><td style=\"text-align: right;\">0.938673</td><td style=\"text-align: right;\"> 0.21588 </td><td style=\"text-align: right;\">0.703653</td><td style=\"text-align: right;\">              0.166856</td><td style=\"text-align: right;\">0.25117 </td><td style=\"text-align: right;\">0.0630865</td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20230516_144637                         </td><td style=\"text-align: right;\">0.719884</td><td style=\"text-align: right;\"> 0.340631</td><td style=\"text-align: right;\">0.257164</td><td style=\"text-align: right;\">              0.331575</td><td style=\"text-align: right;\">0.315379</td><td style=\"text-align: right;\">0.0994637</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7cf17b",
   "metadata": {},
   "source": [
    "## Ensemble Exploration\n",
    "\n",
    "To understand how the ensemble works, let's take a peek inside the Stacked Ensemble \"All Models\" model. The \"All Models\" ensemble is an ensemble of all of the individual models in the AutoML run. This is often the top performing model on the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cecbed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model ids for all models in the AutoML Leaderboard\n",
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:, 0])\n",
    "\n",
    "# Get the \"All Models\" Stacked Ensemble model\n",
    "se = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])\n",
    "\n",
    "# Get the Stacked Ensemble metalearner model\n",
    "metalearner = se.metalearner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a2112",
   "metadata": {},
   "source": [
    "Examine the variable importance of the metalearner (combiner) algorithm in the ensemble. This shows us how much each base learner is contributing to the ensemble. The AutoML Stacked Ensembles use the default metalearner algorithm (GLM with non-negative weights), so the variable importance of the metalearner is actually the standardized coefficient magnitudes of the GLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efef3324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intercept': -3.789713560811744,\n",
       " 'GBM_4_AutoML_1_20230516_144637': 0.5220457399977181,\n",
       " 'XGBoost_3_AutoML_1_20230516_144637': 0.586644809682851,\n",
       " 'GBM_1_AutoML_1_20230516_144637': 0.25156131625397504,\n",
       " 'GBM_3_AutoML_1_20230516_144637': 0.0,\n",
       " 'GBM_2_AutoML_1_20230516_144637': 0.0,\n",
       " 'XGBoost_2_AutoML_1_20230516_144637': 0.3980974309198202,\n",
       " 'XGBoost_1_AutoML_1_20230516_144637': 0.060469769246236274,\n",
       " 'XRT_1_AutoML_1_20230516_144637': 0.4510262380160032,\n",
       " 'DRF_1_AutoML_1_20230516_144637': 0.29831566783157726,\n",
       " 'GLM_1_AutoML_1_20230516_144637': 0.025304500740685597}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metalearner.coef_norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92d6e70",
   "metadata": {},
   "source": [
    "We can also plot the base learner contributions to the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da906f54",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Line2D' object has no attribute '_legmarker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_62343/2650736139.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %matplotlib inline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmetalearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd_coef_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/h2o/model/model_base.py\u001b[0m in \u001b[0;36mstd_coef_plot\u001b[0;34m(self, num_of_features, server, save_plot_path)\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;31m# Later, the method will be exposed only for models supporting the feature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'StandardCoef'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_std_coef_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_of_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_plot_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_plot_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1557\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mH2OValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Standardized coefficient plot is not available for this type of model (%s).\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/h2o/model/extensions/std_coef.py\u001b[0m in \u001b[0;36m_std_coef_plot\u001b[0;34m(self, num_of_features, server, save_plot_path)\u001b[0m\n\u001b[1;32m     85\u001b[0m                        for color in signage[0:num_of_features]]\n\u001b[1;32m     86\u001b[0m             \u001b[0mlgnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"best\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mlgnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegendHandles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legmarker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_markersize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;31m# if neg create neg legend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"#FF7F0E\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msignage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_of_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"#1F77B4\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msignage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_of_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Line2D' object has no attribute '_legmarker'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "metalearner.std_coef_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b305349",
   "metadata": {},
   "source": [
    "## Save Leader Model\n",
    "\n",
    "There are two ways to save the leader model: binary format and MOJO format. If you're taking your leader model to production, then we'd suggest the MOJO format since it's optimized for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.save_model(aml.leader, path = \"./product_backorders_model_bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.leader.download_mojo(path = \"./\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
