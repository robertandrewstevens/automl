{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e871fb",
   "metadata": {},
   "source": [
    "https://auto.gluon.ai/0.1.0/tutorials/tabular_prediction/tabular-quickstart.html\n",
    "\n",
    "# Predicting Columns in a Table - Quick Start: porto_seguro & freMTPL2freq\n",
    "\n",
    "Via a simple `fit()` call, AutoGluon can produce highly-accurate models to predict the values in one column of a data table based on the rest of the columns’ values. Use AutoGluon with tabular data for both classification and regression problems. This tutorial demonstrates how to use AutoGluon to produce a classification model that predicts whether or not a person’s income exceeds $50,000.\n",
    "\n",
    "To start, import AutoGluon’s `TabularPredictor` and `TabularDataset` classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ef982",
   "metadata": {},
   "source": [
    "(Installed in Terminal using)\n",
    "\n",
    "```\n",
    "> pip3 install --user autogluon\n",
    "```\n",
    "\n",
    "(AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\")\n",
    "\n",
    "```\n",
    "> pip3 install --user bokeh==2.0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1111592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12538ae",
   "metadata": {},
   "source": [
    "Load training data from a CSV file into an AutoGluon Dataset object. This object is essentially equivalent to a Pandas DataFrame and the same methods can be applied to both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf03366a",
   "metadata": {},
   "source": [
    "## Regression (predicting numeric table columns):\n",
    "\n",
    "To demonstrate that `fit()` can also automatically handle regression tasks, we now try to predict the numeric `age` variable in the same table based on the other features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d576a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(\"freMTPL2freq_dataset_train.csv\")\n",
    "test_data = TabularDataset(\"freMTPL2freq_dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ba10d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'autogluon.core.dataset.TabularDataset'>\n",
      "RangeIndex: 474765 entries, 0 to 474764\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   IDpol       474765 non-null  int64  \n",
      " 1   ClaimNb     474765 non-null  int64  \n",
      " 2   Exposure    474765 non-null  float64\n",
      " 3   VehPower    474765 non-null  int64  \n",
      " 4   VehAge      474765 non-null  int64  \n",
      " 5   DrivAge     474765 non-null  int64  \n",
      " 6   BonusMalus  474765 non-null  int64  \n",
      " 7   VehBrand    474765 non-null  object \n",
      " 8   VehGas      474765 non-null  object \n",
      " 9   Area        474765 non-null  object \n",
      " 10  Density     474765 non-null  int64  \n",
      " 11  Region      474765 non-null  object \n",
      "dtypes: float64(1), int64(7), object(4)\n",
      "memory usage: 43.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfa75b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'autogluon.core.dataset.TabularDataset'>\n",
      "RangeIndex: 203226 entries, 0 to 203225\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   IDpol       203226 non-null  float64\n",
      " 1   ClaimNb     203226 non-null  int64  \n",
      " 2   Exposure    203226 non-null  float64\n",
      " 3   VehPower    203226 non-null  int64  \n",
      " 4   VehAge      203226 non-null  int64  \n",
      " 5   DrivAge     203226 non-null  int64  \n",
      " 6   BonusMalus  203226 non-null  int64  \n",
      " 7   VehBrand    203226 non-null  object \n",
      " 8   VehGas      203226 non-null  object \n",
      " 9   Area        203226 non-null  object \n",
      " 10  Density     203226 non-null  int64  \n",
      " 11  Region      203226 non-null  object \n",
      "dtypes: float64(2), int64(6), object(4)\n",
      "memory usage: 18.6+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d3880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of target variable: \n",
      " count    474765.000000\n",
      "mean          0.038583\n",
      "std           0.205458\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max          11.000000\n",
      "Name: ClaimNb, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "target_column = 'ClaimNb'\n",
    "print(\"Summary of target variable: \\n\", train_data[target_column].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8eced7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDpol: The policy ID, so drop it\n",
    "train_data = train_data.drop([\"IDpol\"], axis=1)\n",
    "test_data = test_data.drop([\"IDpol\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5134140b",
   "metadata": {},
   "source": [
    "We again call `fit()`, imposing a time-limit this time (in seconds), and also demonstrate a shorthand method to evaluate the resulting model on the test data (which contain labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96af6e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predict_ClaimNb_1\"\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"agModels-predict_ClaimNb_1/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.9.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu May 4 15:21:22 UTC 2023\n",
      "Train Data Rows:    474765\n",
      "Train Data Columns: 10\n",
      "Label Column: ClaimNb\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    222563.59 MB\n",
      "\tTrain Data (Original)  Memory Usage: 141.07 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1 | ['Exposure']\n",
      "\t\t('int', [])    : 5 | ['VehPower', 'VehAge', 'DrivAge', 'BonusMalus', 'Density']\n",
      "\t\t('object', []) : 4 | ['VehBrand', 'VehGas', 'Area', 'Region']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 3 | ['VehBrand', 'Area', 'Region']\n",
      "\t\t('float', [])     : 1 | ['Exposure']\n",
      "\t\t('int', [])       : 5 | ['VehPower', 'VehAge', 'DrivAge', 'BonusMalus', 'Density']\n",
      "\t\t('int', ['bool']) : 1 | ['VehGas']\n",
      "\t1.3s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 24.69 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.39s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 470017, Val Rows: 4748\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3598.61s of the 3598.61s of remaining time.\n",
      "\t-0.0769\t = Validation score   (-mean_absolute_error)\n",
      "\t4.02s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3593.96s of the 3593.96s of remaining time.\n",
      "\t-0.0764\t = Validation score   (-mean_absolute_error)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3592.51s of the 3592.51s of remaining time.\n",
      "\t-0.0752\t = Validation score   (-mean_absolute_error)\n",
      "\t5.78s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3586.53s of the 3586.53s of remaining time.\n",
      "\t-0.0745\t = Validation score   (-mean_absolute_error)\n",
      "\t2.68s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 3583.64s of the 3583.64s of remaining time.\n",
      "\t-0.0803\t = Validation score   (-mean_absolute_error)\n",
      "\t14.14s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3566.49s of the 3566.49s of remaining time.\n",
      "\t-0.0748\t = Validation score   (-mean_absolute_error)\n",
      "\t44.57s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3521.76s of the 3521.75s of remaining time.\n",
      "\t-0.0783\t = Validation score   (-mean_absolute_error)\n",
      "\t5.86s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3512.77s of the 3512.77s of remaining time.\n",
      "No improvement since epoch 8: early stopping\n",
      "\t-0.0703\t = Validation score   (-mean_absolute_error)\n",
      "\t335.6s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3176.72s of the 3176.72s of remaining time.\n",
      "\t-0.0747\t = Validation score   (-mean_absolute_error)\n",
      "\t4.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3172.17s of the 3172.17s of remaining time.\n",
      "\t-0.0423\t = Validation score   (-mean_absolute_error)\n",
      "\t408.32s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 2763.69s of the 2763.69s of remaining time.\n",
      "\t-0.0746\t = Validation score   (-mean_absolute_error)\n",
      "\t3.55s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 2759.91s of remaining time.\n",
      "\t-0.0423\t = Validation score   (-mean_absolute_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 841.33s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predict_ClaimNb_1/\")\n"
     ]
    }
   ],
   "source": [
    "# specified problem_type to eliminate infering multi-class problem_type, e.g.,\n",
    "#   problem_type=\"regression\"\n",
    "# and increased time_limit to 1 hour\n",
    "predictor_ClaimNb = TabularPredictor(\n",
    "    label=target_column, \n",
    "    path=\"agModels-predict_ClaimNb_1\", \n",
    "    problem_type=\"regression\",\n",
    "    eval_metric=\"mean_absolute_error\",\n",
    ").fit(train_data, time_limit=3600) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee79e43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stever7/.local/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1420: FutureWarning: Calling `predictor.predict_proba` when problem_type=regression will raise an AssertionError starting in AutoGluon v0.8. Please call `predictor.predict` instead.\n",
      "  warnings.warn(\n",
      "Evaluation: mean_absolute_error on test data: -0.039985119318079465\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"mean_absolute_error\": -0.039985119318079465,\n",
      "    \"root_mean_squared_error\": -0.21486121610324158,\n",
      "    \"mean_squared_error\": -0.046165342185363875,\n",
      "    \"r2\": -0.03587427964308243,\n",
      "    \"pearsonr\": 0.010003043367767372,\n",
      "    \"median_absolute_error\": -1.6990729027714646e-12\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_absolute_error': -0.039985119318079465,\n",
       " 'root_mean_squared_error': -0.21486121610324158,\n",
       " 'mean_squared_error': -0.046165342185363875,\n",
       " 'r2': -0.03587427964308243,\n",
       " 'pearsonr': 0.010003043367767372,\n",
       " 'median_absolute_error': -1.6990729027714646e-12}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_ClaimNb.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aadc26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-0.039985</td>\n",
       "      <td>-0.042334</td>\n",
       "      <td>0.835173</td>\n",
       "      <td>0.042401</td>\n",
       "      <td>408.320539</td>\n",
       "      <td>0.835173</td>\n",
       "      <td>0.042401</td>\n",
       "      <td>408.320539</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.039985</td>\n",
       "      <td>-0.042334</td>\n",
       "      <td>0.843122</td>\n",
       "      <td>0.043046</td>\n",
       "      <td>408.731905</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.411366</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-0.067926</td>\n",
       "      <td>-0.070266</td>\n",
       "      <td>1.844203</td>\n",
       "      <td>0.054441</td>\n",
       "      <td>335.601196</td>\n",
       "      <td>1.844203</td>\n",
       "      <td>0.054441</td>\n",
       "      <td>335.601196</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-0.072297</td>\n",
       "      <td>-0.076406</td>\n",
       "      <td>8.450431</td>\n",
       "      <td>0.124074</td>\n",
       "      <td>1.004383</td>\n",
       "      <td>8.450431</td>\n",
       "      <td>0.124074</td>\n",
       "      <td>1.004383</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-0.072425</td>\n",
       "      <td>-0.074476</td>\n",
       "      <td>0.217564</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>2.683523</td>\n",
       "      <td>0.217564</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>2.683523</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-0.072524</td>\n",
       "      <td>-0.074557</td>\n",
       "      <td>0.167122</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>3.549958</td>\n",
       "      <td>0.167122</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>3.549958</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.072578</td>\n",
       "      <td>-0.074781</td>\n",
       "      <td>0.185585</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>44.571321</td>\n",
       "      <td>0.185585</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>44.571321</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.072580</td>\n",
       "      <td>-0.074668</td>\n",
       "      <td>0.729292</td>\n",
       "      <td>0.025859</td>\n",
       "      <td>4.361375</td>\n",
       "      <td>0.729292</td>\n",
       "      <td>0.025859</td>\n",
       "      <td>4.361375</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-0.072947</td>\n",
       "      <td>-0.075217</td>\n",
       "      <td>0.343346</td>\n",
       "      <td>0.022357</td>\n",
       "      <td>5.776668</td>\n",
       "      <td>0.343346</td>\n",
       "      <td>0.022357</td>\n",
       "      <td>5.776668</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-0.073036</td>\n",
       "      <td>-0.076874</td>\n",
       "      <td>5.428477</td>\n",
       "      <td>0.168389</td>\n",
       "      <td>4.019855</td>\n",
       "      <td>5.428477</td>\n",
       "      <td>0.168389</td>\n",
       "      <td>4.019855</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-0.075441</td>\n",
       "      <td>-0.078331</td>\n",
       "      <td>2.309502</td>\n",
       "      <td>0.181983</td>\n",
       "      <td>5.862971</td>\n",
       "      <td>2.309502</td>\n",
       "      <td>0.181983</td>\n",
       "      <td>5.862971</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-0.077546</td>\n",
       "      <td>-0.080284</td>\n",
       "      <td>2.238744</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>14.144878</td>\n",
       "      <td>2.238744</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>14.144878</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0        NeuralNetTorch   -0.039985  -0.042334        0.835173       0.042401   \n",
       "1   WeightedEnsemble_L2   -0.039985  -0.042334        0.843122       0.043046   \n",
       "2       NeuralNetFastAI   -0.067926  -0.070266        1.844203       0.054441   \n",
       "3        KNeighborsDist   -0.072297  -0.076406        8.450431       0.124074   \n",
       "4              LightGBM   -0.072425  -0.074476        0.217564       0.011429   \n",
       "5         LightGBMLarge   -0.072524  -0.074557        0.167122       0.010945   \n",
       "6              CatBoost   -0.072578  -0.074781        0.185585       0.012086   \n",
       "7               XGBoost   -0.072580  -0.074668        0.729292       0.025859   \n",
       "8            LightGBMXT   -0.072947  -0.075217        0.343346       0.022357   \n",
       "9        KNeighborsUnif   -0.073036  -0.076874        5.428477       0.168389   \n",
       "10        ExtraTreesMSE   -0.075441  -0.078331        2.309502       0.181983   \n",
       "11      RandomForestMSE   -0.077546  -0.080284        2.238744       0.143564   \n",
       "\n",
       "      fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   408.320539                 0.835173                0.042401   \n",
       "1   408.731905                 0.007949                0.000645   \n",
       "2   335.601196                 1.844203                0.054441   \n",
       "3     1.004383                 8.450431                0.124074   \n",
       "4     2.683523                 0.217564                0.011429   \n",
       "5     3.549958                 0.167122                0.010945   \n",
       "6    44.571321                 0.185585                0.012086   \n",
       "7     4.361375                 0.729292                0.025859   \n",
       "8     5.776668                 0.343346                0.022357   \n",
       "9     4.019855                 5.428477                0.168389   \n",
       "10    5.862971                 2.309502                0.181983   \n",
       "11   14.144878                 2.238744                0.143564   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0          408.320539            1       True         10  \n",
       "1            0.411366            2       True         12  \n",
       "2          335.601196            1       True          8  \n",
       "3            1.004383            1       True          2  \n",
       "4            2.683523            1       True          4  \n",
       "5            3.549958            1       True         11  \n",
       "6           44.571321            1       True          6  \n",
       "7            4.361375            1       True          9  \n",
       "8            5.776668            1       True          3  \n",
       "9            4.019855            1       True          1  \n",
       "10           5.862971            1       True          7  \n",
       "11          14.144878            1       True          5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_ClaimNb.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918f710",
   "metadata": {},
   "source": [
    "Note that we didn’t need to tell AutoGluon this is a regression problem, it automatically inferred this from the data and reported the appropriate performance metric (RMSE by default). To specify a particular evaluation metric other than the default, set the `eval_metric` argument of `fit()` and AutoGluon will tailor its models to optimize your metric, e.g.,\n",
    "\n",
    "```\n",
    "eval_metric='mean_absolute_error'\n",
    "```` \n",
    "\n",
    "For evaluation metrics where higher values are worse (like RMSE), AutoGluon may sometimes flips their sign and print them as negative values during training (as it internally assumes higher values are better).\n",
    "\n",
    "**Data Formats:** AutoGluon can currently operate on data tables already loaded into Python as pandas DataFrames, or those stored in files of CSV format or Parquet format. If your data live in multiple tables, you will first need to join them into a single table whose rows correspond to statistically independent observations (datapoints) and columns correspond to different features (aka. variables/covariates).\n",
    "\n",
    "Refer to the TabularPredictor documentation to see all of the available methods/options\n",
    "\n",
    "https://auto.gluon.ai/0.1.0/api/autogluon.predictor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cce33a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
