{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e871fb",
   "metadata": {},
   "source": [
    "https://auto.gluon.ai/0.1.0/tutorials/tabular_prediction/tabular-quickstart.html\n",
    "\n",
    "# Predicting Columns in a Table - Quick Start: porto_seguro & freMTPL2freq\n",
    "\n",
    "Via a simple `fit()` call, AutoGluon can produce highly-accurate models to predict the values in one column of a data table based on the rest of the columns’ values. Use AutoGluon with tabular data for both classification and regression problems. This tutorial demonstrates how to use AutoGluon to produce a classification model that predicts whether or not a person’s income exceeds $50,000.\n",
    "\n",
    "To start, import AutoGluon’s `TabularPredictor` and `TabularDataset` classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ef982",
   "metadata": {},
   "source": [
    "(Installed in Terminal using)\n",
    "\n",
    "```\n",
    "> pip3 install --user autogluon\n",
    "```\n",
    "\n",
    "(AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\")\n",
    "\n",
    "```\n",
    "> pip3 install --user bokeh==2.0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1111592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12538ae",
   "metadata": {},
   "source": [
    "Load training data from a CSV file into an AutoGluon Dataset object. This object is essentially equivalent to a Pandas DataFrame and the same methods can be applied to both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa91bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "train_data = TabularDataset(\"porto_train.csv\")\n",
    "test_data = TabularDataset(\"porto_test.csv\")\n",
    "# subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "# train_data = train_data.sample(n=subsample_size, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c640033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de99e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f69249d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'autogluon.core.dataset.TabularDataset'>\n",
      "RangeIndex: 476170 entries, 0 to 476169\n",
      "Data columns (total 60 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   id              476170 non-null  int64  \n",
      " 1   target          476170 non-null  int64  \n",
      " 2   ps_ind_01       476170 non-null  int64  \n",
      " 3   ps_ind_02_cat   476170 non-null  int64  \n",
      " 4   ps_ind_03       476170 non-null  int64  \n",
      " 5   ps_ind_04_cat   476170 non-null  int64  \n",
      " 6   ps_ind_05_cat   476170 non-null  int64  \n",
      " 7   ps_ind_06_bin   476170 non-null  int64  \n",
      " 8   ps_ind_07_bin   476170 non-null  int64  \n",
      " 9   ps_ind_08_bin   476170 non-null  int64  \n",
      " 10  ps_ind_09_bin   476170 non-null  int64  \n",
      " 11  ps_ind_10_bin   476170 non-null  int64  \n",
      " 12  ps_ind_11_bin   476170 non-null  int64  \n",
      " 13  ps_ind_12_bin   476170 non-null  int64  \n",
      " 14  ps_ind_13_bin   476170 non-null  int64  \n",
      " 15  ps_ind_14       476170 non-null  int64  \n",
      " 16  ps_ind_15       476170 non-null  int64  \n",
      " 17  ps_ind_16_bin   476170 non-null  int64  \n",
      " 18  ps_ind_17_bin   476170 non-null  int64  \n",
      " 19  ps_ind_18_bin   476170 non-null  int64  \n",
      " 20  ps_reg_01       476170 non-null  float64\n",
      " 21  ps_reg_02       476170 non-null  float64\n",
      " 22  ps_reg_03       476170 non-null  float64\n",
      " 23  ps_car_01_cat   476170 non-null  int64  \n",
      " 24  ps_car_02_cat   476170 non-null  int64  \n",
      " 25  ps_car_03_cat   476170 non-null  int64  \n",
      " 26  ps_car_04_cat   476170 non-null  int64  \n",
      " 27  ps_car_05_cat   476170 non-null  int64  \n",
      " 28  ps_car_06_cat   476170 non-null  int64  \n",
      " 29  ps_car_07_cat   476170 non-null  int64  \n",
      " 30  ps_car_08_cat   476170 non-null  int64  \n",
      " 31  ps_car_09_cat   476170 non-null  int64  \n",
      " 32  ps_car_10_cat   476170 non-null  int64  \n",
      " 33  ps_car_11_cat   476170 non-null  int64  \n",
      " 34  ps_car_11       476170 non-null  int64  \n",
      " 35  ps_car_12       476170 non-null  float64\n",
      " 36  ps_car_13       476170 non-null  float64\n",
      " 37  ps_car_14       476170 non-null  float64\n",
      " 38  ps_car_15       476170 non-null  float64\n",
      " 39  ps_calc_01      476170 non-null  float64\n",
      " 40  ps_calc_02      476170 non-null  float64\n",
      " 41  ps_calc_03      476170 non-null  float64\n",
      " 42  ps_calc_04      476170 non-null  int64  \n",
      " 43  ps_calc_05      476170 non-null  int64  \n",
      " 44  ps_calc_06      476170 non-null  int64  \n",
      " 45  ps_calc_07      476170 non-null  int64  \n",
      " 46  ps_calc_08      476170 non-null  int64  \n",
      " 47  ps_calc_09      476170 non-null  int64  \n",
      " 48  ps_calc_10      476170 non-null  int64  \n",
      " 49  ps_calc_11      476170 non-null  int64  \n",
      " 50  ps_calc_12      476170 non-null  int64  \n",
      " 51  ps_calc_13      476170 non-null  int64  \n",
      " 52  ps_calc_14      476170 non-null  int64  \n",
      " 53  ps_calc_15_bin  476170 non-null  int64  \n",
      " 54  ps_calc_16_bin  476170 non-null  int64  \n",
      " 55  ps_calc_17_bin  476170 non-null  int64  \n",
      " 56  ps_calc_18_bin  476170 non-null  int64  \n",
      " 57  ps_calc_19_bin  476170 non-null  int64  \n",
      " 58  ps_calc_20_bin  476170 non-null  int64  \n",
      " 59  fold            476170 non-null  int64  \n",
      "dtypes: float64(10), int64(50)\n",
      "memory usage: 218.0 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e2a49d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'autogluon.core.dataset.TabularDataset'>\n",
      "RangeIndex: 119042 entries, 0 to 119041\n",
      "Data columns (total 59 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   id              119042 non-null  int64  \n",
      " 1   target          119042 non-null  int64  \n",
      " 2   ps_ind_01       119042 non-null  int64  \n",
      " 3   ps_ind_02_cat   119042 non-null  int64  \n",
      " 4   ps_ind_03       119042 non-null  int64  \n",
      " 5   ps_ind_04_cat   119042 non-null  int64  \n",
      " 6   ps_ind_05_cat   119042 non-null  int64  \n",
      " 7   ps_ind_06_bin   119042 non-null  int64  \n",
      " 8   ps_ind_07_bin   119042 non-null  int64  \n",
      " 9   ps_ind_08_bin   119042 non-null  int64  \n",
      " 10  ps_ind_09_bin   119042 non-null  int64  \n",
      " 11  ps_ind_10_bin   119042 non-null  int64  \n",
      " 12  ps_ind_11_bin   119042 non-null  int64  \n",
      " 13  ps_ind_12_bin   119042 non-null  int64  \n",
      " 14  ps_ind_13_bin   119042 non-null  int64  \n",
      " 15  ps_ind_14       119042 non-null  int64  \n",
      " 16  ps_ind_15       119042 non-null  int64  \n",
      " 17  ps_ind_16_bin   119042 non-null  int64  \n",
      " 18  ps_ind_17_bin   119042 non-null  int64  \n",
      " 19  ps_ind_18_bin   119042 non-null  int64  \n",
      " 20  ps_reg_01       119042 non-null  float64\n",
      " 21  ps_reg_02       119042 non-null  float64\n",
      " 22  ps_reg_03       119042 non-null  float64\n",
      " 23  ps_car_01_cat   119042 non-null  int64  \n",
      " 24  ps_car_02_cat   119042 non-null  int64  \n",
      " 25  ps_car_03_cat   119042 non-null  int64  \n",
      " 26  ps_car_04_cat   119042 non-null  int64  \n",
      " 27  ps_car_05_cat   119042 non-null  int64  \n",
      " 28  ps_car_06_cat   119042 non-null  int64  \n",
      " 29  ps_car_07_cat   119042 non-null  int64  \n",
      " 30  ps_car_08_cat   119042 non-null  int64  \n",
      " 31  ps_car_09_cat   119042 non-null  int64  \n",
      " 32  ps_car_10_cat   119042 non-null  int64  \n",
      " 33  ps_car_11_cat   119042 non-null  int64  \n",
      " 34  ps_car_11       119042 non-null  int64  \n",
      " 35  ps_car_12       119042 non-null  float64\n",
      " 36  ps_car_13       119042 non-null  float64\n",
      " 37  ps_car_14       119042 non-null  float64\n",
      " 38  ps_car_15       119042 non-null  float64\n",
      " 39  ps_calc_01      119042 non-null  float64\n",
      " 40  ps_calc_02      119042 non-null  float64\n",
      " 41  ps_calc_03      119042 non-null  float64\n",
      " 42  ps_calc_04      119042 non-null  int64  \n",
      " 43  ps_calc_05      119042 non-null  int64  \n",
      " 44  ps_calc_06      119042 non-null  int64  \n",
      " 45  ps_calc_07      119042 non-null  int64  \n",
      " 46  ps_calc_08      119042 non-null  int64  \n",
      " 47  ps_calc_09      119042 non-null  int64  \n",
      " 48  ps_calc_10      119042 non-null  int64  \n",
      " 49  ps_calc_11      119042 non-null  int64  \n",
      " 50  ps_calc_12      119042 non-null  int64  \n",
      " 51  ps_calc_13      119042 non-null  int64  \n",
      " 52  ps_calc_14      119042 non-null  int64  \n",
      " 53  ps_calc_15_bin  119042 non-null  int64  \n",
      " 54  ps_calc_16_bin  119042 non-null  int64  \n",
      " 55  ps_calc_17_bin  119042 non-null  int64  \n",
      " 56  ps_calc_18_bin  119042 non-null  int64  \n",
      " 57  ps_calc_19_bin  119042 non-null  int64  \n",
      " 58  ps_calc_20_bin  119042 non-null  int64  \n",
      "dtypes: float64(10), int64(49)\n",
      "memory usage: 53.6 MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509ba338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_01</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_03</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_15</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_reg_01</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_reg_02</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_reg_03</th>\n",
       "      <td>0.766078</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.580948</td>\n",
       "      <td>0.840759</td>\n",
       "      <td>0.617454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_03_cat</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_04_cat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_05_cat</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_06_cat</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_08_cat</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_10_cat</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_11_cat</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_11</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_12</th>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>0.316070</td>\n",
       "      <td>0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_13</th>\n",
       "      <td>0.618817</td>\n",
       "      <td>0.641586</td>\n",
       "      <td>0.542949</td>\n",
       "      <td>0.565832</td>\n",
       "      <td>0.639683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_14</th>\n",
       "      <td>0.388716</td>\n",
       "      <td>0.347275</td>\n",
       "      <td>0.294958</td>\n",
       "      <td>0.365103</td>\n",
       "      <td>0.368782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_15</th>\n",
       "      <td>2.449490</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.162278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_01</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_02</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_03</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_04</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_05</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_06</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_07</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_08</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_09</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_10</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_11</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_14</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0          1           2          3          4\n",
       "id               9.000000  13.000000   16.000000  17.000000  20.000000\n",
       "target           0.000000   0.000000    0.000000   0.000000   0.000000\n",
       "ps_ind_01        1.000000   5.000000    0.000000   0.000000   2.000000\n",
       "ps_ind_02_cat    1.000000   4.000000    1.000000   2.000000   1.000000\n",
       "ps_ind_03        7.000000   9.000000    2.000000   0.000000   3.000000\n",
       "ps_ind_04_cat    0.000000   1.000000    0.000000   1.000000   1.000000\n",
       "ps_ind_05_cat    0.000000   0.000000    0.000000   0.000000   0.000000\n",
       "ps_ind_06_bin    0.000000   0.000000    1.000000   1.000000   0.000000\n",
       "ps_ind_07_bin    0.000000   0.000000    0.000000   0.000000   1.000000\n",
       "ps_ind_08_bin    1.000000   1.000000    0.000000   0.000000   0.000000\n",
       "ps_ind_09_bin    0.000000   0.000000    0.000000   0.000000   0.000000\n",
       "ps_ind_10_bin    0.000000   0.000000    0.000000   0.000000   0.000000\n",
       "ps_ind_11_bin    0.000000   0.000000    0.000000   0.000000   0.000000\n",
       "ps_ind_12_bin    0.000000   0.000000    0.000000   0.000000   0.000000\n",
       "ps_ind_13_bin    0.000000   0.000000    0.000000   0.000000   0.000000\n",
       "ps_ind_14        0.000000   0.000000    0.000000   0.000000   0.000000\n",
       "ps_ind_15        3.000000  12.000000    8.000000   9.000000   8.000000\n",
       "ps_ind_16_bin    0.000000   1.000000    1.000000   1.000000   1.000000\n",
       "ps_ind_17_bin    0.000000   0.000000    0.000000   0.000000   0.000000\n",
       "ps_ind_18_bin    1.000000   0.000000    0.000000   0.000000   0.000000\n",
       "ps_reg_01        0.800000   0.000000    0.900000   0.700000   0.600000\n",
       "ps_reg_02        0.400000   0.000000    0.200000   0.600000   0.100000\n",
       "ps_reg_03        0.766078  -1.000000    0.580948   0.840759   0.617454\n",
       "ps_car_01_cat   11.000000   7.000000    7.000000  11.000000   6.000000\n",
       "ps_car_02_cat    1.000000   1.000000    1.000000   1.000000   1.000000\n",
       "ps_car_03_cat   -1.000000  -1.000000    0.000000  -1.000000  -1.000000\n",
       "ps_car_04_cat    0.000000   0.000000    0.000000   0.000000   0.000000\n",
       "ps_car_05_cat   -1.000000  -1.000000    1.000000  -1.000000   1.000000\n",
       "ps_car_06_cat   11.000000  14.000000   11.000000  14.000000  11.000000\n",
       "ps_car_07_cat    1.000000   1.000000    1.000000   1.000000   1.000000\n",
       "ps_car_08_cat    1.000000   1.000000    1.000000   1.000000   1.000000\n",
       "ps_car_09_cat    2.000000   2.000000    3.000000   2.000000   0.000000\n",
       "ps_car_10_cat    1.000000   1.000000    1.000000   1.000000   1.000000\n",
       "ps_car_11_cat   19.000000  60.000000  104.000000  82.000000  99.000000\n",
       "ps_car_11        3.000000   1.000000    1.000000   3.000000   2.000000\n",
       "ps_car_12        0.316228   0.316228    0.374166   0.316070   0.316228\n",
       "ps_car_13        0.618817   0.641586    0.542949   0.565832   0.639683\n",
       "ps_car_14        0.388716   0.347275    0.294958   0.365103   0.368782\n",
       "ps_car_15        2.449490   3.316625    2.000000   2.000000   3.162278\n",
       "ps_calc_01       0.300000   0.500000    0.600000   0.400000   0.200000\n",
       "ps_calc_02       0.100000   0.700000    0.900000   0.600000   0.600000\n",
       "ps_calc_03       0.300000   0.100000    0.100000   0.000000   0.500000\n",
       "ps_calc_04       2.000000   2.000000    2.000000   2.000000   2.000000\n",
       "ps_calc_05       1.000000   2.000000    4.000000   2.000000   2.000000\n",
       "ps_calc_06       9.000000   9.000000    7.000000   6.000000   8.000000\n",
       "ps_calc_07       5.000000   1.000000    1.000000   3.000000   1.000000\n",
       "ps_calc_08       8.000000   8.000000    8.000000  10.000000   8.000000\n",
       "ps_calc_09       1.000000   2.000000    4.000000   2.000000   3.000000\n",
       "ps_calc_10       7.000000   7.000000    2.000000  12.000000  10.000000\n",
       "ps_calc_11       3.000000   4.000000    2.000000   3.000000   3.000000\n",
       "ps_calc_12       1.000000   2.000000    2.000000   1.000000   0.000000\n",
       "ps_calc_13       1.000000   7.000000    4.000000   1.000000   0.000000\n",
       "ps_calc_14       9.000000   7.000000    9.000000   3.000000  10.000000\n",
       "ps_calc_15_bin   0.000000   0.000000    0.000000   0.000000   0.000000\n",
       "ps_calc_16_bin   1.000000   1.000000    0.000000   0.000000   1.000000\n",
       "ps_calc_17_bin   1.000000   1.000000    0.000000   0.000000   0.000000\n",
       "ps_calc_18_bin   0.000000   0.000000    0.000000   1.000000   0.000000\n",
       "ps_calc_19_bin   1.000000   1.000000    0.000000   1.000000   1.000000\n",
       "ps_calc_20_bin   0.000000   0.000000    0.000000   0.000000   0.000000\n",
       "fold             5.000000   1.000000    3.000000   2.000000   1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdfa225",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2433ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.replace(-1, np.nan)\n",
    "test_data = test_data.replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "848e3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dc8951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop([\"id\", \"fold\"], axis=1)\n",
    "test_data = test_data.drop([\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fdec6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476170, 58)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51962a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119042, 58)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9602ba26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps_ind_02_cat',\n",
       " 'ps_ind_04_cat',\n",
       " 'ps_ind_05_cat',\n",
       " 'ps_car_01_cat',\n",
       " 'ps_car_02_cat',\n",
       " 'ps_car_03_cat',\n",
       " 'ps_car_04_cat',\n",
       " 'ps_car_05_cat',\n",
       " 'ps_car_06_cat',\n",
       " 'ps_car_07_cat',\n",
       " 'ps_car_08_cat',\n",
       " 'ps_car_09_cat',\n",
       " 'ps_car_10_cat',\n",
       " 'ps_car_11_cat']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars = [col for col in train_data.columns if 'cat' in col]\n",
    "cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "710066ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_vars:\n",
    "    test_data[col] = test_data[col].astype('category')\n",
    "    \n",
    "cat_vars = cat_vars + [\"target\"]\n",
    "\n",
    "for col in cat_vars:\n",
    "    train_data[col] = train_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84afa907",
   "metadata": {},
   "source": [
    "Note that we loaded data from a CSV file stored in the cloud (AWS s3 bucket), but you can you specify a local file-path instead if you have already downloaded the CSV file to your own machine (e.g., using `wget`). Each row in the table `train_data` corresponds to a single training example. In this particular dataset, each row corresponds to an individual person, and the columns contain various characteristics reported during a census.\n",
    "\n",
    "Let’s first use these features to predict whether the person’s income exceeds $50,000 or not, which is recorded in the `class` column of this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5517e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count     476170\n",
      "unique         2\n",
      "top            0\n",
      "freq      458811\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label = \"target\"\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373a3d04",
   "metadata": {},
   "source": [
    "Now use AutoGluon to train multiple models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17398a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictClass_porto_1\"\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (476170 samples, 170.95 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"agModels-predictClass_porto_1/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.9.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu May 4 15:21:22 UTC 2023\n",
      "Train Data Rows:    476170\n",
      "Train Data Columns: 57\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    248786.46 MB\n",
      "\tTrain Data (Original)  Memory Usage: 170.47 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 18 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 14 | ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', ...]\n",
      "\t\t('float', [])    : 11 | ['ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_car_11', 'ps_car_12', ...]\n",
      "\t\t('int', [])      : 32 | ['ps_ind_01', 'ps_ind_03', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 13 | ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', ...]\n",
      "\t\t('float', [])     : 11 | ['ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_car_11', 'ps_car_12', ...]\n",
      "\t\t('int', [])       : 15 | ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_calc_04', ...]\n",
      "\t\t('int', ['bool']) : 18 | ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', ...]\n",
      "\t2.4s = Fit runtime\n",
      "\t57 features in original data used to generate 57 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 113.81 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.97s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 471408, Val Rows: 4762\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.5039\t = Validation score   (roc_auc)\n",
      "\t3.13s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.5047\t = Validation score   (roc_auc)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.5919\t = Validation score   (roc_auc)\n",
      "\t3.88s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.5818\t = Validation score   (roc_auc)\n",
      "\t1.79s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.583\t = Validation score   (roc_auc)\n",
      "\t15.36s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.5819\t = Validation score   (roc_auc)\n",
      "\t15.29s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.602\t = Validation score   (roc_auc)\n",
      "\t47.68s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.5851\t = Validation score   (roc_auc)\n",
      "\t9.28s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6018\t = Validation score   (roc_auc)\n",
      "\t9.8s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.5816\t = Validation score   (roc_auc)\n",
      "\t468.26s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.6015\t = Validation score   (roc_auc)\n",
      "\t7.55s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5942\t = Validation score   (roc_auc)\n",
      "\t283.06s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.5871\t = Validation score   (roc_auc)\n",
      "\t3.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6115\t = Validation score   (roc_auc)\n",
      "\t1.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 890.09s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass_porto_1/\")\n"
     ]
    }
   ],
   "source": [
    "save_path = 'agModels-predictClass_porto_1'  # specifies folder to store trained models\n",
    "\n",
    "predictor = TabularPredictor(label=label, path=save_path, eval_metric=\"roc_auc\").fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5845395",
   "metadata": {},
   "source": [
    "Next, load separate test data to demonstrate how to make predictions on new examples at inference time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "940f4863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ps_ind_01 ps_ind_02_cat  ps_ind_03 ps_ind_04_cat ps_ind_05_cat  \\\n",
       "0          2           2.0          5           1.0           0.0   \n",
       "1          5           1.0          4           0.0           0.0   \n",
       "2          5           1.0         11           0.0           0.0   \n",
       "3          5           1.0          8           0.0           0.0   \n",
       "4          0           1.0          2           0.0           0.0   \n",
       "\n",
       "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ps_ind_10_bin  \\\n",
       "0              0              1              0              0              0   \n",
       "1              0              0              0              1              0   \n",
       "2              0              0              0              1              0   \n",
       "3              1              0              0              0              0   \n",
       "4              1              0              0              0              0   \n",
       "\n",
       "   ...  ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0  ...           9           1           5           8               0   \n",
       "1  ...           4           2           0           9               0   \n",
       "2  ...           4           1           3           9               0   \n",
       "3  ...           3           1           6           5               0   \n",
       "4  ...           7           2           2           4               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               0               1               1   \n",
       "2               0               0               0               1   \n",
       "3               0               0               1               0   \n",
       "4               1               0               0               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               1  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "\n",
    "y_test = test_data[label]  # values to predict\n",
    "\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f119623",
   "metadata": {},
   "source": [
    "We use our trained models to make predictions on the new data and then evaluate performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f619e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  \n",
      "                0         1\n",
      "0       0.951413  0.048587\n",
      "1       0.953420  0.046580\n",
      "2       0.972430  0.027570\n",
      "3       0.982235  0.017765\n",
      "4       0.978142  0.021858\n",
      "...          ...       ...\n",
      "119037  0.962012  0.037988\n",
      "119038  0.979733  0.020267\n",
      "119039  0.966375  0.033625\n",
      "119040  0.971194  0.028806\n",
      "119041  0.975856  0.024144\n",
      "\n",
      "[119042 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stever7/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Evaluation: roc_auc on test data: 0.6314907429408757\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"roc_auc\": 0.6314907429408757,\n",
      "    \"accuracy\": 0.9635842811780716,\n",
      "    \"balanced_accuracy\": 0.5,\n",
      "    \"mcc\": 0.0,\n",
      "    \"f1\": 0.0,\n",
      "    \"precision\": 0.0,\n",
      "    \"recall\": 0.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "\n",
    "# y_pred = predictor.predict(test_data_nolab)\n",
    "y_pred = predictor.predict_proba(test_data_nolab)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc81f5b",
   "metadata": {},
   "source": [
    "Now you’re ready to try AutoGluon on your own tabular datasets. As long as they’re stored in a popular format like CSV, you should be able to achieve strong predictive performance with just 2 lines of code:\n",
    "\n",
    "```\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "predictor = TabularPredictor(label=<variable-name>).fit(train_data=<file-name>)\n",
    "```\n",
    "\n",
    "Note: This simple call to `fit()` is intended for your first prototype model. In a subsequent section, we’ll demonstrate how to maximize predictive performance by additionally specifying two `fit()` arguments: `presets` and `eval_metric`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48dc563",
   "metadata": {},
   "source": [
    "## Description of `fit()`:\n",
    "\n",
    "Here we discuss what happened during `fit()`.\n",
    "\n",
    "Since there are only two possible values of the `class` variable, this was a binary classification problem, for which an appropriate performance metric is accuracy. AutoGluon automatically infers this as well as the type of each feature (i.e., which columns contain continuous numbers vs. discrete categories). AutogGluon can also automatically handle common issues like missing data and rescaling feature values.\n",
    "\n",
    "We did not specify separate validation data and so AutoGluon automatically choses a random training/validation split of the data. The data used for validation is seperated from the training data and is used to determine the models and hyperparameter-values that produce the best results. Rather than just a single model, AutoGluon trains multiple models and ensembles them together to ensure superior predictive performance.\n",
    "\n",
    "By default, AutoGluon tries to fit various types of models including neural networks and tree ensembles. Each type of model has various hyperparameters, which traditionally, the user would have to specify. AutoGluon automates this process.\n",
    "\n",
    "AutoGluon automatically and iteratively tests values for hyperparameters to produce the best performance on the validation data. This involves repeatedly training models under different hyperparameter settings and evaluating their performance. This process can be computationally-intensive, so `fit()` can parallelize this process across multiple threads (and machines if distributed resources are available). To control runtimes, you can specify various arguments in `fit()` as demonstrated in the subsequent In-Depth tutorial.\n",
    "\n",
    "For tabular problems, `fit()` returns a Predictor object. For classification, you can easily output predicted class probabilities instead of predicted classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68b6cade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.951413</td>\n",
       "      <td>0.048587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.953420</td>\n",
       "      <td>0.046580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.972430</td>\n",
       "      <td>0.027570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.982235</td>\n",
       "      <td>0.017765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.978142</td>\n",
       "      <td>0.021858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.951413  0.048587\n",
       "1  0.953420  0.046580\n",
       "2  0.972430  0.027570\n",
       "3  0.982235  0.017765\n",
       "4  0.978142  0.021858"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs = predictor.predict_proba(test_data_nolab)\n",
    "pred_probs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04805b4",
   "metadata": {},
   "source": [
    "Besides inference, this object can also summarize what happened during fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26c9acf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2   0.611518       0.311911  349.463983                0.001177           1.372172            2       True         14\n",
      "1              CatBoost   0.602004       0.026258   47.678899                0.026258          47.678899            1       True          7\n",
      "2        ExtraTreesEntr   0.601840       0.170448    9.796823                0.170448           9.796823            1       True          9\n",
      "3               XGBoost   0.601470       0.042089    7.551451                0.042089           7.551451            1       True         11\n",
      "4        NeuralNetTorch   0.594228       0.071939  283.064638                0.071939         283.064638            1       True         12\n",
      "5            LightGBMXT   0.591881       0.012810    3.881337                0.012810           3.881337            1       True          3\n",
      "6         LightGBMLarge   0.587142       0.014340    3.021576                0.014340           3.021576            1       True         13\n",
      "7        ExtraTreesGini   0.585093       0.177928    9.282799                0.177928           9.282799            1       True          8\n",
      "8      RandomForestGini   0.582968       0.154796   15.364313                0.154796          15.364313            1       True          5\n",
      "9      RandomForestEntr   0.581938       0.154517   15.293576                0.154517          15.293576            1       True          6\n",
      "10             LightGBM   0.581836       0.011281    1.789302                0.011281           1.789302            1       True          4\n",
      "11      NeuralNetFastAI   0.581631       0.071112  468.257171                0.071112         468.257171            1       True         10\n",
      "12       KNeighborsDist   0.504697       0.812247    0.284666                0.812247           0.284666            1       True          2\n",
      "13       KNeighborsUnif   0.503897       0.725032    3.126115                0.725032           3.126115            1       True          1\n",
      "Number of models trained: 14\n",
      "Types of models trained:\n",
      "{'LGBModel', 'NNFastAiTabularModel', 'KNNModel', 'CatBoostModel', 'XGBoostModel', 'WeightedEnsembleModel', 'RFModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  : 13 | ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', ...]\n",
      "('float', [])     : 11 | ['ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_car_11', 'ps_car_12', ...]\n",
      "('int', [])       : 15 | ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_calc_04', ...]\n",
      "('int', ['bool']) : 18 | ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', ...]\n",
      "Plot summary of models saved to file: agModels-predictClass_porto_1/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148874a7",
   "metadata": {},
   "source": [
    "From this summary, we can see that AutoGluon trained many different types of models as well as an ensemble of the best-performing models. The summary also describes the actual models that were trained during fit and how well each model performed on the held-out validation data. We can view what properties AutoGluon automatically inferred about our prediction task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9e82c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  binary\n",
      "AutoGluon identified the following types of features:\n",
      "('category', [])  : 13 | ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', ...]\n",
      "('float', [])     : 11 | ['ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_car_11', 'ps_car_12', ...]\n",
      "('int', [])       : 15 | ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_calc_04', ...]\n",
      "('int', ['bool']) : 18 | ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', ...]\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c2758",
   "metadata": {},
   "source": [
    "AutoGluon correctly recognized our prediction problem to be a binary classification task and decided that variables such as `age` should be represented as integers, whereas variables such as `workclass` should be represented as categorical objects. The `feature_metadata` attribute allows you to see the inferred data type of each predictive variable after preprocessing (this is it’s raw dtype; some features may also be associated with additional special dtypes if produced via feature-engineering, e.g. numerical representations of a datetime/text column).\n",
    "\n",
    "We can evaluate the performance of each individual trained model on our (labeled) test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4cc05e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.635058</td>\n",
       "      <td>0.602004</td>\n",
       "      <td>0.274688</td>\n",
       "      <td>0.026258</td>\n",
       "      <td>47.678899</td>\n",
       "      <td>0.274688</td>\n",
       "      <td>0.026258</td>\n",
       "      <td>47.678899</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.634824</td>\n",
       "      <td>0.601470</td>\n",
       "      <td>0.951324</td>\n",
       "      <td>0.042089</td>\n",
       "      <td>7.551451</td>\n",
       "      <td>0.951324</td>\n",
       "      <td>0.042089</td>\n",
       "      <td>7.551451</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.631491</td>\n",
       "      <td>0.611518</td>\n",
       "      <td>3.624071</td>\n",
       "      <td>0.311911</td>\n",
       "      <td>349.463983</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>1.372172</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.625603</td>\n",
       "      <td>0.581631</td>\n",
       "      <td>1.454859</td>\n",
       "      <td>0.071112</td>\n",
       "      <td>468.257171</td>\n",
       "      <td>1.454859</td>\n",
       "      <td>0.071112</td>\n",
       "      <td>468.257171</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.621983</td>\n",
       "      <td>0.591881</td>\n",
       "      <td>0.122447</td>\n",
       "      <td>0.012810</td>\n",
       "      <td>3.881337</td>\n",
       "      <td>0.122447</td>\n",
       "      <td>0.012810</td>\n",
       "      <td>3.881337</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.621455</td>\n",
       "      <td>0.587142</td>\n",
       "      <td>0.119742</td>\n",
       "      <td>0.014340</td>\n",
       "      <td>3.021576</td>\n",
       "      <td>0.119742</td>\n",
       "      <td>0.014340</td>\n",
       "      <td>3.021576</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.620740</td>\n",
       "      <td>0.594228</td>\n",
       "      <td>1.273045</td>\n",
       "      <td>0.071939</td>\n",
       "      <td>283.064638</td>\n",
       "      <td>1.273045</td>\n",
       "      <td>0.071939</td>\n",
       "      <td>283.064638</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.617411</td>\n",
       "      <td>0.581836</td>\n",
       "      <td>0.105527</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>1.789302</td>\n",
       "      <td>0.105527</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>1.789302</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.612614</td>\n",
       "      <td>0.601840</td>\n",
       "      <td>1.116702</td>\n",
       "      <td>0.170448</td>\n",
       "      <td>9.796823</td>\n",
       "      <td>1.116702</td>\n",
       "      <td>0.170448</td>\n",
       "      <td>9.796823</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.585093</td>\n",
       "      <td>1.302161</td>\n",
       "      <td>0.177928</td>\n",
       "      <td>9.282799</td>\n",
       "      <td>1.302161</td>\n",
       "      <td>0.177928</td>\n",
       "      <td>9.282799</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.607943</td>\n",
       "      <td>0.581938</td>\n",
       "      <td>1.133135</td>\n",
       "      <td>0.154517</td>\n",
       "      <td>15.293576</td>\n",
       "      <td>1.133135</td>\n",
       "      <td>0.154517</td>\n",
       "      <td>15.293576</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.606315</td>\n",
       "      <td>0.582968</td>\n",
       "      <td>1.365688</td>\n",
       "      <td>0.154796</td>\n",
       "      <td>15.364313</td>\n",
       "      <td>1.365688</td>\n",
       "      <td>0.154796</td>\n",
       "      <td>15.364313</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.508486</td>\n",
       "      <td>0.503897</td>\n",
       "      <td>7.812171</td>\n",
       "      <td>0.725032</td>\n",
       "      <td>3.126115</td>\n",
       "      <td>7.812171</td>\n",
       "      <td>0.725032</td>\n",
       "      <td>3.126115</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.507837</td>\n",
       "      <td>0.504697</td>\n",
       "      <td>7.792835</td>\n",
       "      <td>0.812247</td>\n",
       "      <td>0.284666</td>\n",
       "      <td>7.792835</td>\n",
       "      <td>0.812247</td>\n",
       "      <td>0.284666</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0              CatBoost    0.635058   0.602004        0.274688       0.026258   \n",
       "1               XGBoost    0.634824   0.601470        0.951324       0.042089   \n",
       "2   WeightedEnsemble_L2    0.631491   0.611518        3.624071       0.311911   \n",
       "3       NeuralNetFastAI    0.625603   0.581631        1.454859       0.071112   \n",
       "4            LightGBMXT    0.621983   0.591881        0.122447       0.012810   \n",
       "5         LightGBMLarge    0.621455   0.587142        0.119742       0.014340   \n",
       "6        NeuralNetTorch    0.620740   0.594228        1.273045       0.071939   \n",
       "7              LightGBM    0.617411   0.581836        0.105527       0.011281   \n",
       "8        ExtraTreesEntr    0.612614   0.601840        1.116702       0.170448   \n",
       "9        ExtraTreesGini    0.609756   0.585093        1.302161       0.177928   \n",
       "10     RandomForestEntr    0.607943   0.581938        1.133135       0.154517   \n",
       "11     RandomForestGini    0.606315   0.582968        1.365688       0.154796   \n",
       "12       KNeighborsUnif    0.508486   0.503897        7.812171       0.725032   \n",
       "13       KNeighborsDist    0.507837   0.504697        7.792835       0.812247   \n",
       "\n",
       "      fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0    47.678899                 0.274688                0.026258   \n",
       "1     7.551451                 0.951324                0.042089   \n",
       "2   349.463983                 0.008312                0.001177   \n",
       "3   468.257171                 1.454859                0.071112   \n",
       "4     3.881337                 0.122447                0.012810   \n",
       "5     3.021576                 0.119742                0.014340   \n",
       "6   283.064638                 1.273045                0.071939   \n",
       "7     1.789302                 0.105527                0.011281   \n",
       "8     9.796823                 1.116702                0.170448   \n",
       "9     9.282799                 1.302161                0.177928   \n",
       "10   15.293576                 1.133135                0.154517   \n",
       "11   15.364313                 1.365688                0.154796   \n",
       "12    3.126115                 7.812171                0.725032   \n",
       "13    0.284666                 7.792835                0.812247   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           47.678899            1       True          7  \n",
       "1            7.551451            1       True         11  \n",
       "2            1.372172            2       True         14  \n",
       "3          468.257171            1       True         10  \n",
       "4            3.881337            1       True          3  \n",
       "5            3.021576            1       True         13  \n",
       "6          283.064638            1       True         12  \n",
       "7            1.789302            1       True          4  \n",
       "8            9.796823            1       True          9  \n",
       "9            9.282799            1       True          8  \n",
       "10          15.293576            1       True          6  \n",
       "11          15.364313            1       True          5  \n",
       "12           3.126115            1       True          1  \n",
       "13           0.284666            1       True          2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b418dc7a",
   "metadata": {},
   "source": [
    "When we call `predict()`, AutoGluon automatically predicts with the model that displayed the best performance on validation data (i.e. the weighted-ensemble). We can instead specify which model to use for predictions like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57c91a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "119037    0\n",
       "119038    0\n",
       "119039    0\n",
       "119040    0\n",
       "119041    0\n",
       "Name: target, Length: 119042, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(test_data, model='LightGBM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a2614c",
   "metadata": {},
   "source": [
    "Above the scores of predictive performance were based on a default evaluation metric (accuracy for binary classification). Performance in certain applications may be measured by different metrics than the ones AutoGluon optimizes for by default. If you know the metric that counts in your application, you should specify it as demonstrated in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397511ee",
   "metadata": {},
   "source": [
    "## Maximizing predictive performance\n",
    "\n",
    "Note: You should not call `fit()` with entirely default arguments if you are benchmarking AutoGluon-Tabular or hoping to maximize its accuracy. To get the best predictive accuracy with AutoGluon, you should generally use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47082cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230703_223843/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230703_223843/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.9.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu May 4 15:21:22 UTC 2023\n",
      "Train Data Rows:    476170\n",
      "Train Data Columns: 57\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    231758.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 170.47 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 18 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 14 | ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', ...]\n",
      "\t\t('float', [])    : 11 | ['ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_car_11', 'ps_car_12', ...]\n",
      "\t\t('int', [])      : 32 | ['ps_ind_01', 'ps_ind_03', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 13 | ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', ...]\n",
      "\t\t('float', [])     : 11 | ['ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_car_11', 'ps_car_12', ...]\n",
      "\t\t('int', [])       : 15 | ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_calc_04', ...]\n",
      "\t\t('int', ['bool']) : 18 | ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', ...]\n",
      "\t2.5s = Fit runtime\n",
      "\t57 features in original data used to generate 57 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 113.81 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3596.96s of the 3596.96s of remaining time.\n",
      "\t0.5077\t = Validation score   (roc_auc)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t30.44s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3565.33s of the 3565.33s of remaining time.\n",
      "\t0.5076\t = Validation score   (roc_auc)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t30.88s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3533.21s of the 3533.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6327\t = Validation score   (roc_auc)\n",
      "\t73.3s\t = Training   runtime\n",
      "\t1.24s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3428.03s of the 3428.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n"
     ]
    }
   ],
   "source": [
    "time_limit = 60*60  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "metric = \"roc_auc\"  # specify your evaluation metric here\n",
    "predictor = TabularPredictor(label, eval_metric=metric).fit(train_data, time_limit=time_limit, presets='best_quality')\n",
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579d5c39",
   "metadata": {},
   "source": [
    "This command implements the following strategy to maximize accuracy:\n",
    "\n",
    "- Specify the argument `presets='best_quality'`, which allows AutoGluon to automatically construct powerful model ensembles based on stacking/bagging, and will greatly improve the resulting predictions if granted sufficient training time\n",
    "    + https://arxiv.org/abs/2003.06505\n",
    "    + The default value of `presets` is `'medium_quality_faster_train'`, which produces less accurate models but facilitates faster prototyping\n",
    "    + With `presets`, you can flexibly prioritize predictive accuracy vs. training/inference speed\n",
    "    + For example, if you care less about predictive performance and want to quickly deploy a basic model, consider using: `presets=['good_quality_faster_inference_only_refit', 'optimize_for_deployment']`.\n",
    "\n",
    "- Provide the `eval_metric` if you know what metric will be used to evaluate predictions in your application\n",
    "    + Some other non-default metrics you might use include things like: `'f1'` (for binary classification), `'roc_auc'` (for binary classification), `'log_loss'` (for classification), `'mean_absolute_error'` (for regression), `'median_absolute_error'` (for regression)\n",
    "    + You can also define your own custom metric function, see examples in the folder: `autogluon/core/metrics/`\n",
    "\n",
    "- Include all your data in `train_data` and do not provide `tuning_data`\n",
    "    + AutoGluon will split the data more intelligently to fit its needs\n",
    "\n",
    "- Do not specify the `hyperparameter_tune_kwargs` argument (counterintuitively, hyperparameter tuning is not the best way to spend a limited training time budgets, as model ensembling is often superior)\n",
    "    + We recommend you only use `hyperparameter_tune_kwargs` if your goal is to deploy a single model rather than an ensemble\n",
    "\n",
    "- Do not specify `hyperparameters` argument (allow AutoGluon to adaptively select which models/hyperparameters to use)\n",
    "\n",
    "- Set `time_limit` to the longest amount of time (in seconds) that you are willing to wait\n",
    "    + AutoGluon’s predictive performance improves the longer `fit()` is allowed to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf03366a",
   "metadata": {},
   "source": [
    "## Regression (predicting numeric table columns):\n",
    "\n",
    "To demonstrate that `fit()` can also automatically handle regression tasks, we now try to predict the numeric `age` variable in the same table based on the other features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(\"freMTPL2freq_dataset_train.csv\")\n",
    "test_data = TabularDataset(\"freMTPL2freq_dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa75b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'ClaimNb'\n",
    "print(\"Summary of target variable: \\n\", train_data[target_column].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eced7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDpol: The policy ID, so drop it\n",
    "train_data = train_data.drop([\"IDpol\"], axis=1)\n",
    "test_data = test_data.drop([\"IDpol\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5134140b",
   "metadata": {},
   "source": [
    "We again call `fit()`, imposing a time-limit this time (in seconds), and also demonstrate a shorthand method to evaluate the resulting model on the test data (which contain labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specified problem_type to eliminate infering multi-class problem_type, e.g.,\n",
    "#   problem_type=\"regression\"\n",
    "# and increased time_limit to 1 hour\n",
    "predictor_ClaimNb = TabularPredictor(\n",
    "    label=target_column, \n",
    "    path=\"agModels-predict_ClaimNb_1\", \n",
    "    problem_type=\"regression\",\n",
    "    eval_metric=\"mean_absolute_error\",\n",
    ").fit(train_data, time_limit=3600) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee79e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_ClaimNb.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aadc26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_ClaimNb.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918f710",
   "metadata": {},
   "source": [
    "Note that we didn’t need to tell AutoGluon this is a regression problem, it automatically inferred this from the data and reported the appropriate performance metric (RMSE by default). To specify a particular evaluation metric other than the default, set the `eval_metric` argument of `fit()` and AutoGluon will tailor its models to optimize your metric, e.g.,\n",
    "\n",
    "```\n",
    "eval_metric='mean_absolute_error'\n",
    "```` \n",
    "\n",
    "For evaluation metrics where higher values are worse (like RMSE), AutoGluon may sometimes flips their sign and print them as negative values during training (as it internally assumes higher values are better).\n",
    "\n",
    "**Data Formats:** AutoGluon can currently operate on data tables already loaded into Python as pandas DataFrames, or those stored in files of CSV format or Parquet format. If your data live in multiple tables, you will first need to join them into a single table whose rows correspond to statistically independent observations (datapoints) and columns correspond to different features (aka. variables/covariates).\n",
    "\n",
    "Refer to the TabularPredictor documentation to see all of the available methods/options\n",
    "\n",
    "https://auto.gluon.ai/0.1.0/api/autogluon.predictor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cce33a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
